{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "864da17e-d7c3-4a3e-9f8c-e9674d6a4c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_date, when, countDistinct, count\n",
    "from pyspark.sql.functions import split, explode, trim, col, lit, length\n",
    "from pyspark.sql.functions import current_date, row_number, regexp_replace, coalesce\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33fc75ec-9d7f-4c15-a97a-e564a28bd059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"dbfs:/FileStore/tables/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6a3d241-6391-4e67-bcbb-2a1a24f58128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/Imdb_Movie_Dataset-1.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "# quote <-- Important to handle commas correctly\n",
    "df = (\n",
    "    spark.read.format(file_type)\n",
    "    .option(\"inferSchema\", infer_schema)\n",
    "    .option(\"header\", first_row_is_header)\n",
    "    .option(\"sep\", delimiter)\n",
    "    .option(\"quote\", '\"')\n",
    "    .option(\"escape\", '\"')\n",
    "    .load(file_location)\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26c74481-9126-42f2-a267-5ab03c6b9ed6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbf62d8-0c84-450c-90bd-627224370609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Can we predict the box office revenue of a movie before it is released?\n",
    "This project explores that question by building a machine learning regression model using Apache Spark MLlib to predict the revenue of a movie based on features such as budget, genre, popularity, vote average, and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e89c4a15-f0ab-4666-b250-05a9b94a05ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b21d397b-c2be-484e-9bf2-e8c3cc760718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset Schema with Correct Types\n",
    "\n",
    "| Column                  | Current Type | Correct Type      |\n",
    "|-------------------------|--------------|-------------------|\n",
    "| id                      | integer      | integer           |\n",
    "| title                   | string       | string            |\n",
    "| vote_average            | string       | **double** (float)|\n",
    "| vote_count              | string       | **integer**       |\n",
    "| status                  | string       | string            |\n",
    "| release_date            | string       | **date**          |\n",
    "| revenue                 | string       | **long** (integer)|\n",
    "| runtime                 | string       | **integer**       |\n",
    "| adult                   | string       | **boolean**       |\n",
    "| budget                  | string       | **long** (integer)|\n",
    "| imdb_id                 | string       | string            |\n",
    "| original_language       | string       | string            |\n",
    "| original_title          | string       | string            |\n",
    "| overview                | string       | string            |\n",
    "| popularity              | string       | **double** (float)|\n",
    "| tagline                 | string       | string            |\n",
    "| genres                  | string       | **array<string>** |\n",
    "| production_companies    | string       | **array<string>** |\n",
    "| production_countries    | string       | **array<string>** |\n",
    "| spoken_languages        | string       | **array<string>** |\n",
    "| keywords                | string       | **array<string>** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6ad152-b75a-436d-be25-7214af00a08e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column\n",
    "def missing_values_table_spark(df):\n",
    "\n",
    "    # Calculate the total missing values for each column\n",
    "    mis_val = df.select([F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "    # Convert to Pandas for easier handling\n",
    "    mis_val_pd = mis_val.toPandas().transpose()\n",
    "\n",
    "    # Calculate the percentage of missing values for each column\n",
    "    mis_val_percent = (mis_val_pd[0] / df.count()) * 100\n",
    "\n",
    "    # Create a new table combining count and percentage\n",
    "    mis_val_table = pd.concat([mis_val_pd, mis_val_percent], axis=1)\n",
    "    mis_val_table.columns = ['Missing Values', '% of Total Values']\n",
    "\n",
    "    # Keep only columns with >0% missing, sort descending, round\n",
    "    mis_val_table = (\n",
    "        mis_val_table[mis_val_table['% of Total Values'] > 0]\n",
    "        .sort_values('% of Total Values', ascending=False)\n",
    "        .round(1)\n",
    "    )\n",
    "\n",
    "    # Reset index so that original column names become a column\n",
    "    mis_val_table = mis_val_table.reset_index().rename(columns={'index': 'Column'})\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Your selected dataframe has {len(df.columns)} columns.\\n\"\n",
    "          f\"There are {mis_val_table.shape[0]} columns that have missing values.\")\n",
    "\n",
    "    return mis_val_table\n",
    "\n",
    "# Usage\n",
    "missing_values = missing_values_table_spark(df)\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6f4046a-33b0-4d2d-b1e7-81217631d849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_missing_values(mis_val_table, title):\n",
    "    \"\"\"\n",
    "    Plots the percentage of missing values per feature, showing feature names on the x-axis.\n",
    "    Assumes `mis_val_table` has a column 'Column' with the feature names and\n",
    "    '% of Total Values' with the missing-value percentages.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Use the 'Column' column for x-labels\n",
    "    sns.barplot(\n",
    "        data=mis_val_table,\n",
    "        x='Column',\n",
    "        y='% of Total Values'\n",
    "    )\n",
    "\n",
    "    # Rotate the x labels for better readability\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('% of Total Values')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the missing values with feature names shown\n",
    "plot_missing_values(missing_values, title='Percentage of Missing Values by Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e652ecfc-17ac-4a52-ad3d-979e3d6ca106",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Updated function to include a 'Column' column instead of using the index\n",
    "def zero_values_table_spark(df):\n",
    "\n",
    "    # For each column, count how many values equal zero\n",
    "    zero_counts = df.select([F.sum(F.when(F.col(c) == 0, 1).otherwise(0)).alias(c) for c in df.columns])\n",
    "\n",
    "    # Convert result to Pandas for easier manipulation\n",
    "    zero_counts_pd = zero_counts.toPandas().transpose()\n",
    "\n",
    "    # Compute percentage\n",
    "    row_count = df.count()\n",
    "    zero_percent = (zero_counts_pd[0] / row_count) * 100\n",
    "\n",
    "    # Create summary table\n",
    "    zero_table = pd.concat([zero_counts_pd, zero_percent], axis=1)\n",
    "    zero_table.columns = ['Zero Values', '% of Total Values']\n",
    "\n",
    "    # Keep only columns with zeros, sort and round\n",
    "    zero_table = (\n",
    "        zero_table[zero_table['Zero Values'] > 0]\n",
    "        .sort_values('% of Total Values', ascending=False)\n",
    "        .round(1)\n",
    "    )\n",
    "\n",
    "    # Reset index so column names appear as a column\n",
    "    zero_table = zero_table.reset_index().rename(columns={'index': 'Column'})\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Your selected dataframe has {len(df.columns)} columns.\\n\"\n",
    "          f\"There are {zero_table.shape[0]} columns that have zero values.\")\n",
    "\n",
    "    return zero_table\n",
    "\n",
    "# Use the function\n",
    "zero_values = zero_values_table_spark(df)\n",
    "display(zero_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31e3459a-84e3-4dd9-9b30-4bd96d04b182",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_zero_values(zero_table, title):\n",
    "    \"\"\"\n",
    "    Plots the percentage of zero values per feature, using the 'Column' column\n",
    "    for the x-axis labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    sns.barplot(\n",
    "        data=zero_table,\n",
    "        x='Column',\n",
    "        y='% of Total Values'\n",
    "    )\n",
    "\n",
    "    # Rotate x-labels for readability\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('% of Total Values')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# print\n",
    "plot_zero_values(zero_values, title='Percentage of Zero Values by Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d4fcbd1-9542-4e96-b9a0-7b521434b56a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Missing or Zero Values Summary\n",
    "\n",
    "### Missing Values\n",
    "These columns have significant number of null entries:\n",
    "- **tagline** (85.4% missing)  \n",
    "- **keywords** (72.1% missing)  \n",
    "- **production_companies** (54.2% missing)\n",
    "- **imdb_id** (46.5% missing)  \n",
    "- **production_countries** (44.2% missing)  \n",
    "- **spoken_languages** (~42% missing)  \n",
    "- **genres** (39.6% missing)  \n",
    "- **overview** (20.6% missing)  \n",
    "- **release_date** (17.3% missing)\n",
    "\n",
    "### Zero Values\n",
    "The following columns contain a substantial fraction of zeros:\n",
    "- **revenue** (98% zeros)  \n",
    "- **budget** (94.6% zeros)  \n",
    "- **adult** (90.7% zeros)\n",
    "- **vote average** (66.6% zeros)\n",
    "- **vote_count** (66.5%)   \n",
    "- **runtime** (28% zeros) \n",
    "- **popularity** (13.2% zeros)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a392b49-d8af-4fc7-b0f8-0510326e6572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##ID and IMDB_ID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb550b6b-0251-4e3e-9793-ce52018f13bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, we will check for duplicates by **id** and **imdb_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2457031-1eb8-43d1-8245-79a37fba045c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate total and distinct counts\n",
    "total_rows = df.count()\n",
    "unique_id = df.select(countDistinct(\"id\")).collect()[0][0]\n",
    "unique_imdb_id = df.select(countDistinct(\"imdb_id\")).collect()[0][0]\n",
    "\n",
    "# Calculate duplicated counts\n",
    "duplicated_id = total_rows - unique_id\n",
    "duplicated_imdb_id = total_rows - unique_imdb_id\n",
    "\n",
    "# Print results\n",
    "print(f\"Total duplicated IDs: {duplicated_id}\")\n",
    "print(f\"Total duplicated IMDB IDs: {duplicated_imdb_id}\")\n",
    "\n",
    "# Display examples of duplicated 'id' rows\n",
    "dup_id_vals = (\n",
    "    df\n",
    "    .groupBy(\"id\")\n",
    "    .count()\n",
    "    .filter(col(\"count\") > 1)\n",
    "    .select(\"id\")\n",
    ")\n",
    "dup_id_rows = (\n",
    "    df\n",
    "    .join(dup_id_vals, on=\"id\", how=\"inner\")\n",
    "    .orderBy(\"id\")\n",
    ")\n",
    "print(\"Examples of duplicated 'id' rows:\")\n",
    "display(dup_id_rows.limit(10))\n",
    "\n",
    "# Display examples of duplicated 'imdb_id' rows \n",
    "dup_imdb_vals = (\n",
    "    df\n",
    "    .groupBy(\"imdb_id\")\n",
    "    .count()\n",
    "    .filter(col(\"count\") > 1)\n",
    "    .select(\"imdb_id\")\n",
    ")\n",
    "dup_imdb_rows = (\n",
    "    df\n",
    "    .join(dup_imdb_vals, on=\"imdb_id\", how=\"inner\")\n",
    "    .orderBy(\"imdb_id\")\n",
    ")\n",
    "print(\"Examples of duplicated 'imdb_id' rows:\")\n",
    "display(dup_imdb_rows.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41ef82b7-adc8-4769-bcde-d369d6d5aade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count how many \"None\" strings are in imdb_id\n",
    "none_count = df.filter(col(\"imdb_id\") == \"None\").count()\n",
    "\n",
    "# Replace \"None\" strings with actual nulls\n",
    "df = df.withColumn(\n",
    "    \"imdb_id\",\n",
    "    when(col(\"imdb_id\") == \"None\", None)\n",
    "      .otherwise(col(\"imdb_id\"))\n",
    ")\n",
    "\n",
    "# Print how many values were set to null\n",
    "print(f\"Number of 'None' values replaced with null in 'imdb_id': {none_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4666fc4b-7173-40d3-8832-ac7abb270974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate counts for non-null imdb_id values\n",
    "non_null_rows = df.filter(col(\"imdb_id\").isNotNull()).count()\n",
    "unique_non_null = (\n",
    "    df\n",
    "    .filter(col(\"imdb_id\").isNotNull())\n",
    "    .select(countDistinct(\"imdb_id\"))\n",
    "    .collect()[0][0]\n",
    ")\n",
    "duplicated_imdb_id = non_null_rows - unique_non_null\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total non-null imdb_id rows: {non_null_rows}\")\n",
    "print(f\"Total duplicated IMDB IDs (excluding nulls): {duplicated_imdb_id}\")\n",
    "\n",
    "# Display examples of duplicated 'imdb_id' rows\n",
    "dup_imdb_vals = (\n",
    "    df\n",
    "    .filter(col(\"imdb_id\").isNotNull())\n",
    "    .groupBy(\"imdb_id\")\n",
    "    .count()\n",
    "    .filter(col(\"count\") > 1)\n",
    "    .select(\"imdb_id\")\n",
    ")\n",
    "\n",
    "dup_imdb_rows = (\n",
    "    df\n",
    "    .join(dup_imdb_vals, on=\"imdb_id\", how=\"inner\")\n",
    "    .orderBy(\"imdb_id\")\n",
    ")\n",
    "\n",
    "print(\"Examples of duplicated 'imdb_id' rows:\")\n",
    "display(dup_imdb_rows.limit(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eacda5c8-5629-496b-9e9d-b8d6bc0723da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Turns out that the duplicated rows by **id** column are in fact duplicates. \n",
    "- We will deduplicate and leave only the row with the lest number of null values.\n",
    "\n",
    "When it comes to **imdb_id**, those also concern the same movies but with original and translated titles. \n",
    "- We will deduplicate using the same logic as we used with **id**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79dfc3aa-07d4-4d0d-bf7c-3ff957d992ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def drop_duplicates_keep_least_null(df, id_col=\"id\"):\n",
    "    \"\"\"\n",
    "    Remove duplicate rows among those with non-null `id_col`, keeping the row with the fewest null values.\n",
    "    Rows where `id_col` is null are left untouched.\n",
    "    Prints how many rows were dropped among non-null IDs.\n",
    "    \"\"\"\n",
    "    # Split into rows with and without an ID\n",
    "    non_null_df = df.filter(col(id_col).isNotNull())\n",
    "    null_df     = df.filter(col(id_col).isNull())\n",
    "    \n",
    "    # Count non-null rows before deduplication\n",
    "    orig_count = non_null_df.count()\n",
    "    \n",
    "    # For each row, count how many columns are null\n",
    "    null_count_expr = sum(\n",
    "        when(col(c).isNull(), 1).otherwise(0) for c in non_null_df.columns\n",
    "    ).alias(\"_null_count\")\n",
    "    nn_with_nulls = non_null_df.withColumn(\"_null_count\", null_count_expr)\n",
    "    \n",
    "    # Within each id group, rank rows by null_count ascending\n",
    "    window = Window.partitionBy(id_col).orderBy(col(\"_null_count\").asc())\n",
    "    ranked = nn_with_nulls.withColumn(\"_rn\", row_number().over(window))\n",
    "    \n",
    "    # Keep only the first row for each id (fewest nulls), drop helper cols\n",
    "    deduped_non_null = (\n",
    "        ranked\n",
    "        .filter(col(\"_rn\") == 1)\n",
    "        .drop(\"_null_count\", \"_rn\")\n",
    "    )\n",
    "    \n",
    "    # Count how many non-null rows were dropped\n",
    "    new_count = deduped_non_null.count()\n",
    "    dropped = orig_count - new_count\n",
    "    print(f\"Dropped {dropped} duplicate rows among non-null '{id_col}'.\")\n",
    "    \n",
    "    # Combine back with the untouched null-ID rows\n",
    "    result_df = deduped_non_null.unionByName(null_df)\n",
    "    return result_df\n",
    "\n",
    "# Use the function to deduplicate by \"id\", preserving rows with null id\n",
    "df = drop_duplicates_keep_least_null(df, id_col=\"id\")\n",
    "\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "489555d1-1941-4a9e-851c-c137400f9b4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now drop duplicates by imdb_id\n",
    "df = drop_duplicates_keep_least_null(df, id_col=\"imdb_id\")\n",
    "\n",
    "# Inspect a few rows to confirm\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae2dc19a-5c09-4fdd-a8b0-80376a3cf789",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check - recalculate duplicates\n",
    "# Total rows\n",
    "total_rows = df.count()\n",
    "\n",
    "# id duplicates (id never null)\n",
    "unique_id = df.select(countDistinct(\"id\")).collect()[0][0]\n",
    "duplicated_id = total_rows - unique_id\n",
    "\n",
    "# imdb_id duplicates (exclude null/\"None\")\n",
    "valid_imdb = df.filter(col(\"imdb_id\").isNotNull() & (col(\"imdb_id\") != \"None\"))\n",
    "total_valid = valid_imdb.count()\n",
    "unique_imdb = valid_imdb.select(countDistinct(\"imdb_id\")).collect()[0][0]\n",
    "duplicated_imdb_id = total_valid - unique_imdb\n",
    "\n",
    "print(f\"Total duplicated IDs: {duplicated_id}\")\n",
    "print(f\"Total duplicated IMDB IDs (excluding nulls): {duplicated_imdb_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e12df235-9329-4ab1-89b8-55955f8de42a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, **id** and **imdb_id** columns are deduplicated. Their datatype is correct, so no need for further changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c50663fa-2ba1-413b-b5c3-efd42bebf700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa6e7057-eba7-4a5e-89ca-bdce6a5b1e00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count null, empty, and \"None\"/\"none\" titles\n",
    "null_count = df.filter(col(\"title\").isNull()).count()\n",
    "empty_count = df.filter((col(\"title\") == \"\") | (col(\"title\") == \" \")).count()\n",
    "none_count = df.filter((col(\"title\") == \"None\") | (col(\"title\") == \"none\")).count()\n",
    "\n",
    "print(f\"Null titles: {null_count}\")\n",
    "print(f\"Empty titles: {empty_count}\")\n",
    "print(f\"None titles: {none_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70e8f1c5-a4dd-421f-90c4-b51542c28635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Title length distribution\n",
    "title_len_df = df.withColumn(\"title_length\", length(col(\"title\")))\n",
    "min_len = title_len_df.agg({\"title_length\": \"min\"}).collect()[0][0]\n",
    "max_len = title_len_df.agg({\"title_length\": \"max\"}).collect()[0][0]\n",
    "median_len = title_len_df.approxQuantile(\"title_length\", [0.5], 0.01)[0]\n",
    "print(f\"Title length — min: {min_len}, median: {median_len:.0f}, max: {max_len}\")\n",
    "\n",
    "# Show extremes\n",
    "print(\"Longest titles:\")\n",
    "display(\n",
    "    title_len_df\n",
    "    .orderBy(col(\"title_length\").desc())\n",
    "    .select(\"id\", \"title\", \"title_length\")\n",
    "    .limit(5)\n",
    ")\n",
    "print(\"Shortest non-empty titles:\")\n",
    "display(\n",
    "    title_len_df\n",
    "    .filter(col(\"title\").isNotNull() & (col(\"title\") != \"\"))\n",
    "    .orderBy(col(\"title_length\").asc())\n",
    "    .select(\"id\", \"title\", \"title_length\")\n",
    "    .limit(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1074f5a3-8548-478e-a9dd-bbd254933499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**title** column does not have any missing values and has the right data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9108ef2c-2f45-49f8-a9c9-5dcf67f1ee66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##VOTE_AVERAGE and VOTE_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d8a1c1-8b75-4552-8e95-039cc631cfa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, and \"None\"/\"none\" counts for vote_average and vote_count\n",
    "total = df.count()\n",
    "\n",
    "for cname in [\"vote_average\", \"vote_count\"]:\n",
    "    nulls   = df.filter(col(cname).isNull()).count()\n",
    "    empties = df.filter((col(cname) == \"\") | (col(cname) == \" \")).count()\n",
    "    nones   = df.filter(col(cname).isin(\"None\", \"none\")).count()\n",
    "    \n",
    "    print(\n",
    "        f\"{cname}: total={total}, \"\n",
    "        f\"nulls={nulls}, \"\n",
    "        f\"empty strings={empties}, \"\n",
    "        f\"'None'/'none' strings={nones}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7d74b81-ab61-4444-98e8-1eb1a7e82810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, we need to cast **vote_average** and **vote_count** into correct data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8638e52f-a60b-40aa-bf45-75229216e89f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast vote_average to double and vote_count to integer\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"vote_average\", col(\"vote_average\").cast(\"double\"))\n",
    "    .withColumn(\"vote_count\",    col(\"vote_count\").cast(\"integer\"))\n",
    ")\n",
    "\n",
    "# Verify schema\n",
    "df.select(\"vote_average\", \"vote_count\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b91c8ec-3049-4b06-94f1-d4b89fac9dc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count instances where vote_average == 0\n",
    "count_avg_zero = df.filter(col(\"vote_average\") == 0).count()\n",
    "print(f\"Number of rows with vote_average == 0: {count_avg_zero}\")\n",
    "\n",
    "# Count instances where vote_count == 0\n",
    "count_count_zero = df.filter(col(\"vote_count\") == 0).count()\n",
    "print(f\"Number of rows with vote_count == 0: {count_count_zero}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d6c0358-e331-40b5-ad82-8b64cc6f4af5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "IMDb’s user rating system allows you to assign any whole-number score from 1 (the lowest) up to 10 (the highest) for any movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a98cc555-3168-48f5-943f-80457f87803b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Movies with vote_average below the allowed minimum (1)\n",
    "below_allowed = df.filter(col(\"vote_average\") < 1)\n",
    "count_below = below_allowed.count()\n",
    "print(f\"Number of movies with vote_average below 1: {count_below}\")\n",
    "\n",
    "# Movies with vote_average above the allowed maximum (10)\n",
    "above_allowed = df.filter(col(\"vote_average\") > 10)\n",
    "count_above = above_allowed.count()\n",
    "print(f\"Number of movies with vote_average above 10: {count_above}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b093a6c-d802-463a-a4dc-d1d942dedfd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace those invalid vote_average values with null\n",
    "df = df.withColumn(\n",
    "    \"vote_average\",\n",
    "    when(col(\"vote_average\") < 1, None)\n",
    "     .otherwise(col(\"vote_average\"))\n",
    ")\n",
    "\n",
    "# Verify none remain\n",
    "remaining_invalid = df.filter(col(\"vote_average\") < 1).count()\n",
    "print(f\"Remaining vote_average < 1 after cleanup: {remaining_invalid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9e05d31-f443-4303-a532-e9985bd2c8a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Movies where vote_count == 0 but vote_average != 0\n",
    "cond = df.filter((col(\"vote_count\") == 0) & (col(\"vote_average\") != 0))\n",
    "count = cond.count()\n",
    "print(f\"Number of movies with vote_count == 0 and vote_average != 0: {count}\")\n",
    "# Display all columns for a few examples\n",
    "display(cond.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd115e98-cd52-4609-be7b-0bfc0943aa9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count how many rows have vote_count == 0\n",
    "zero_count = df.filter(col(\"vote_count\") == 0).count()\n",
    "print(f\"Found {zero_count} rows with vote_count == 0; setting vote_average to null for these.\")\n",
    "\n",
    "# Replace vote_average with null where vote_count is zero\n",
    "df = df.withColumn(\n",
    "    \"vote_average\",\n",
    "    when(col(\"vote_count\") == 0, None)\n",
    "     .otherwise(col(\"vote_average\"))\n",
    ")\n",
    "\n",
    "# Verify that no row with vote_count == 0 still has a non-null vote_average\n",
    "remaining = df.filter((col(\"vote_count\") == 0) & col(\"vote_average\").isNotNull()).count()\n",
    "print(f\"Remaining rows with vote_count == 0 and non-null vote_average: {remaining}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b498b50-310a-4c29-a07e-08e894e4f909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Examples where vote_average == 0\n",
    "count_avg_zero = df.filter(col(\"vote_average\") == 0).count()\n",
    "print(f\"Number of rows with vote_average == 0: {count_avg_zero}\")\n",
    "\n",
    "# Examples where vote_count == 0\n",
    "count_count_zero = df.filter(col(\"vote_count\") == 0).count()\n",
    "print(f\"Number of rows with vote_count == 0: {count_count_zero}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c73b85d-9cc0-4424-9eea-b7c344fa3712",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert only the needed columns to Pandas to avoid memory issues\n",
    "df_plot = df.select(\"vote_average\", \"vote_count\").dropna().toPandas()\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot vote_average histogram\n",
    "sns.histplot(df_plot['vote_average'], bins=20, kde=True, ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Distribution of Vote Average')\n",
    "axes[0].set_xlabel('Vote Average')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Plot vote_count histogram (log scale)\n",
    "sns.histplot(df_plot['vote_count'], bins=50, kde=False, ax=axes[1], color='salmon')\n",
    "axes[1].set_title('Distribution of Vote Count')\n",
    "axes[1].set_xlabel('Vote Count')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_yscale('log')  # log scale for better readability of skewed data\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf90d00e-8873-4741-aa08-3f6c292a40ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The distribution for **vote_average** looks almost normal, with a bump around 5 and 6–7, which aligns with typical average ratings on platforms like IMDb or TMDB.\n",
    "\n",
    "When it comes to **vote_count**, there's a long tail of movies with thousands of votes, likely the popular ones. However, a big portion of movies did not receive any votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c9d7fc-2908-44b1-a6be-d6d413ac7554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## STATUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a52918-99d0-48db-a303-6a58bdda9f34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**status** is in correct data type. First, let's check for distinct values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "404fa734-bf8b-4663-934b-4e8498494816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count distinct non-null statuses\n",
    "distinct_status_count = df.filter(col(\"status\").isNotNull()).select(\"status\").distinct().count()\n",
    "print(f\"Number of distinct 'status' values (excluding nulls): {distinct_status_count}\")\n",
    "\n",
    "# Show frequency of each status\n",
    "status_counts = df.groupBy(\"status\").count().orderBy(col(\"count\").desc())\n",
    "print(\"Counts per status:\")\n",
    "display(status_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7782ee78-916c-4591-af81-a1c428d751e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate average and median revenue by status\n",
    "status_revenue_stats = (\n",
    "    df\n",
    "    .groupBy(\"status\")\n",
    "    .agg(\n",
    "        F.avg(\"revenue\").alias(\"average_revenue\"),\n",
    "        F.expr(\"percentile_approx(revenue, 0.5)\").alias(\"median_revenue\")\n",
    "    )\n",
    "    .orderBy(\"status\")\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display(status_revenue_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3877d795-d98f-4794-8d2a-46eff11fe475",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**We need to decide whether to predict the revenue of movies with all statuses or just the ones released**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7ed264-468b-42bf-b4ea-4cbf2a957096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## RELEASE DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5ac962e-bc77-407d-91f9-7f543320146e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, we need to handle the data type of **release_date**. Upon initial feature investigation, we realized that some dates might be in US formats and some in EU. We will need to hadle it appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29e6fa66-5399-4321-8d61-8007aaa297ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, and \"None\"/\"none\" counts for release_date\n",
    "total_rows    = df.count()\n",
    "null_count    = df.filter(col(\"release_date\").isNull()).count()\n",
    "empty_count   = df.filter((col(\"release_date\") == \"\") | (col(\"release_date\") == \" \")).count()\n",
    "none_count    = df.filter(col(\"release_date\").isin(\"None\", \"none\")).count()\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Null release_date values          : {null_count}\")\n",
    "print(f\"Empty-string release_date values  : {empty_count}\")\n",
    "print(f\"'None'/'none' release_date values : {none_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc18f00-d931-4500-ab70-4ca963121f0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Switch back to the old, pre–Spark-3.0 date parser behavior\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# Trim whitespace and normalize separators (remove spaces around -, /, .)\n",
    "df = df.withColumn(\n",
    "    \"release_date_norm\",\n",
    "    regexp_replace(\n",
    "        trim(col(\"release_date\")),\n",
    "        r\"\\s*([/\\-\\.])\\s*\",\n",
    "        r\"$1\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Try parsing with a variety of common date formats\n",
    "df = df.withColumn(\n",
    "    \"release_date_parsed\",\n",
    "    coalesce(\n",
    "        to_date(col(\"release_date_norm\"), \"yyyy-MM-dd\"),\n",
    "        to_date(col(\"release_date_norm\"), \"yyyy/MM/dd\"),\n",
    "        to_date(col(\"release_date_norm\"), \"yyyy.MM.dd\"),\n",
    "        to_date(col(\"release_date_norm\"), \"MM-dd-yyyy\"),\n",
    "        to_date(col(\"release_date_norm\"), \"MM/dd/yyyy\"),\n",
    "        to_date(col(\"release_date_norm\"), \"MM.dd.yyyy\"),\n",
    "        to_date(col(\"release_date_norm\"), \"dd-MM-yyyy\"),\n",
    "        to_date(col(\"release_date_norm\"), \"dd/MM/yyyy\"),\n",
    "        to_date(col(\"release_date_norm\"), \"dd.MM.yyyy\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# How many rows actually parsed to a non-null date?\n",
    "total = df.count()\n",
    "parsed_non_null = df.filter(col(\"release_date_parsed\").isNotNull()).count()\n",
    "parsed_null     = total - parsed_non_null\n",
    "\n",
    "print(f\"Total rows:                {total}\")\n",
    "print(f\"Rows parsed successfully:  {parsed_non_null}\")\n",
    "print(f\"Rows that failed to parse: {parsed_null}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa64121c-1145-4221-9727-bdc5f09bd556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Replace the old column with the parsed one since all the rows accepted the correct type\n",
    "df = df.drop(\"release_date\").withColumnRenamed(\"release_date_parsed\", \"release_date\")\n",
    "\n",
    "# Display the DataFrame with the parsed release_date column\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3967d446-9352-4795-87c4-5bce58433f38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# print df\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd02067a-fa2c-4203-847e-90c0a2309718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print the schema to see the data type\n",
    "df.select(\"release_date\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "779f1d70-3310-4eea-8cbf-5dd61633f21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check for future release dates (dates beyond today)\n",
    "future_movies = df.filter(col(\"release_date\") > current_date())\n",
    "\n",
    "# Filter movies released before 1888-01-01\n",
    "old_movies = df.filter(col(\"release_date\") < lit(\"1888-01-01\"))\n",
    "\n",
    "# Count and print the result\n",
    "count_future = future_movies.count()\n",
    "print(f\"Number of movies released after today: {count_future}\")\n",
    "count_old = old_movies.count()\n",
    "print(f\"Number of movies released before 1888: {count_old}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65071197-2778-4b21-a821-a001c5dd1e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display 30 movies with selected columns\n",
    "display(\n",
    "    future_movies\n",
    "    .select(\"id\", \"title\", \"status\", \"release_date\")\n",
    "    .limit(30)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a63e7c2-79b4-4714-ad50-4eb43801294a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**A little fuck up with casting the type probably. Will revisit later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45bed956-5ad9-4530-8465-54528c4987ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display a few examples \n",
    "display(old_movies.limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "528caea8-435a-49be-a902-25d6de681768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The movies released before 1888 turn out to be time-laps photography or similar techniques to capture movemement. Therefore, we will leave them in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f20f2367-4b0d-46e5-b162-225cc6415a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ba5664-6c2b-47c2-978c-5e6a36de39ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Export current DataFrame to CSV as a checkpoint\n",
    "output_path = \"/FileStore/tables/df_checkpoint\"\n",
    "\n",
    "# Coalesce to 1 file (optional), write with header\n",
    "df.coalesce(1) \\\n",
    "  .write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .csv(output_path)\n",
    "\n",
    "print(f\"Checkpoint written to {output_path}/ (use Data → DBFS to download the CSV part file)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07d7a3ee-99fe-4d50-874e-d376e1c95169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Reload the checkpoint CSV back into a DataFrame\n",
    "checkpoint_path = \"/FileStore/tables/df_checkpoint\"\n",
    "\n",
    "# Read the CSV back in (with header and schema inference)\n",
    "df_checkpoint = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(checkpoint_path)\n",
    "\n",
    "# (Optional) Replace your working df with the checkpointed one\n",
    "df = df_checkpoint\n",
    "\n",
    "# Verify load\n",
    "print(\"Checkpoint schema:\")\n",
    "df.printSchema()\n",
    "print(f\"Checkpoint row count: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f47bfcaf-da56-4aa1-86cb-9ca709eed9a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REVENUE and BUDGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afd05dd8-ed23-47c7-b3b4-a6eecfe2e5dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Both **revenue** and **budget** are currently in string data type. We need them both as integers. (Alternatively, we could cast them to float point numbers, however, we do not need to be decimal point specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca4ea5fb-2519-4291-a9de-a0051d79ed8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, and \"None\"/\"none\" counts for revenue and budget\n",
    "total = df.count()\n",
    "\n",
    "for cname in [\"revenue\", \"budget\"]:\n",
    "    nulls   = df.filter(col(cname).isNull()).count()\n",
    "    empties = df.filter((col(cname) == \"\") |(col(cname) == \" \")).count()\n",
    "    nones   = df.filter(col(cname).isin(\"None\", \"none\")).count()\n",
    "    zeros   = df.filter(col(cname) == 0).count()\n",
    "    \n",
    "    print(\n",
    "        f\"{cname}: total={total}, \"\n",
    "        f\"nulls={nulls}, \"\n",
    "        f\"empty strings={empties}, \"\n",
    "        f\"'None'/'none' strings={nones}, \"\n",
    "        f\"zeros={zeros}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80618ade-ef4a-4c64-82b2-0440e5b93754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast revenue and budget to long (64-bit integer)\n",
    "df = df.withColumn(\n",
    "        \"revenue\", col(\"revenue\").cast(\"long\")\n",
    "    ).withColumn(\n",
    "        \"budget\",  col(\"budget\").cast(\"long\")\n",
    "    )\n",
    "\n",
    "# Verify that the types have been updated\n",
    "df.select(\"revenue\", \"budget\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6260ef0e-3312-476e-a413-46e2708e28f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter \n",
    "df_money = df.filter((col(\"budget\") > 0) & (col(\"revenue\") > 0))\n",
    "\n",
    "# Select and convert necessary columns to Pandas\n",
    "df_money_pd = df_money.select(\"budget\", \"revenue\").toPandas()\n",
    "\n",
    "# Plot original distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Budget distribution\n",
    "sns.histplot(df_money_pd['budget'], bins=100, ax=axes[0], color='orange')\n",
    "axes[0].set_title('Budget Distribution')\n",
    "axes[0].set_xlabel('Budget ($)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Revenue distribution\n",
    "sns.histplot(df_money_pd['revenue'], bins=100, ax=axes[1], color='blue')\n",
    "axes[1].set_title('Revenue Distribution')\n",
    "axes[1].set_xlabel('Revenue ($)')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dcb362d-2602-4e94-b5ea-79b340d62eeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter Spark DataFrame for positive budget and revenue\n",
    "df_money = df.filter((col(\"budget\") > 0) & (col(\"revenue\") > 0))\n",
    "\n",
    "# Convert to Pandas\n",
    "df_money_pd = df_money.select(\"budget\", \"revenue\").toPandas()\n",
    "\n",
    "# Apply log10 transformation\n",
    "df_money_pd['log_budget'] = np.log10(df_money_pd['budget'])\n",
    "df_money_pd['log_revenue'] = np.log10(df_money_pd['revenue'])\n",
    "\n",
    "# Plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.histplot(df_money_pd['log_budget'], bins=50, ax=axes[0], color='orange')\n",
    "axes[0].set_title('Log10 Budget Distribution')\n",
    "axes[0].set_xlabel('Log10(Budget)')\n",
    "\n",
    "sns.histplot(df_money_pd['log_revenue'], bins=50, ax=axes[1], color='blue')\n",
    "axes[1].set_title('Log10 Revenue Distribution')\n",
    "axes[1].set_xlabel('Log10(Revenue)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc89a265-c7ea-46a4-9c92-af8cb1103af4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Budget and Revenue (log₁₀) Distributions\n",
    "\n",
    "Log₁₀(Budget)\n",
    "The bulk of film budgets cluster around log₁₀(budget) ≈ 6.5–7.5, i.e. budgets of roughly \\$3 million to \\$30 million. Most budgets fall between log₁₀ ≈ 5 (≈ \\$100 k) and log₁₀ ≈ 8 (≈ \\$100 million). There is a long left‐hand tail extending down toward zero (very low‐budget or no‐budget films), and a shorter right tail tapering off beyond log₁₀ ≈ 8. Small peaks around log₁₀ ≈ 2–3 (\\$100–\\$1 000 budgets) and log₁₀ ≈ 4–5 (\\$10 000–\\$100 000) likely correspond to micro‐budget productions.\n",
    "\n",
    "Log₁₀(Revenue)\n",
    "Revenues tend to concentrate around log₁₀(revenue) ≈ 7–8, i.e. \\$10 million to \\$100 million. Revenues span from very low figures (log₁₀ ≈ 0–2, under \\$100–\\$100) up to blockbuster grosses (log₁₀ ≈ 9+, over \\$1 billion), though the extreme high end thins out sharply. The distribution is right‐skewed, with a heavy left tail of low‐earning films and a tapering right tail of big‐blockbusters. A visible bump near log₁₀ ≈ 4–5 (\\$10 000–\\$100 000) suggests a cluster of modest indie releases, and occasional spikes around log₁₀ ≈ 2 (\\$100–\\$1 000) reflect very small‐scale runs or data artifacts.\n",
    "\n",
    "Overall, both distributions are left-skewed on the log scale, with most films clustering in the mid‐range budgets and revenues, but with long tails toward both the ultra‐low and the ultra‐high ends.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0ca02d-0029-4755-87cb-a436f6cfdf57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Movies with revenue == 0 but budget != 0\n",
    "zero_rev_nonzero_budget = df.filter((col(\"revenue\") == 0) & (col(\"budget\") != 0))\n",
    "count_zero_rev_nonzero_budget = zero_rev_nonzero_budget.count()\n",
    "print(f\"Movies with revenue = 0 and budget != 0: {count_zero_rev_nonzero_budget}\")\n",
    "display(zero_rev_nonzero_budget.limit(5))\n",
    "\n",
    "# Movies with budget == 0 but revenue != 0\n",
    "zero_budget_nonzero_rev = df.filter((col(\"budget\") == 0) & (col(\"revenue\") != 0))\n",
    "count_zero_budget_nonzero_rev = zero_budget_nonzero_rev.count()\n",
    "print(f\"Movies with budget = 0 and revenue != 0: {count_zero_budget_nonzero_rev}\")\n",
    "display(zero_budget_nonzero_rev.limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5547339a-0591-40cb-9287-47a31665234d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Movies with negative budget\n",
    "neg_budget_count = df.filter(col(\"budget\") < 0).count()\n",
    "print(f\"Number of movies with negative budget: {neg_budget_count}\")\n",
    "\n",
    "#  Movies with negative revenue\n",
    "neg_revenue_count = df.filter(col(\"revenue\") < 0).count()\n",
    "print(f\"Number of movies with negative revenue: {neg_revenue_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1ce920c-73ca-4294-b4d2-92804067d3bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bf83bd-b91e-45a7-ae5b-53978ba53d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First of all, we need to cast **runtime** into integer type. Then, we will check if there are any inconsistencies in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53969d32-da3e-4f11-b6f9-47d577e9ef21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, \"None\"/\"none\", and zero counts for runtime\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"runtime\").isNull()).count()\n",
    "empties = df.filter((col(\"runtime\") == \"\") |(col(\"runtime\") == \" \")).count()\n",
    "nones   = df.filter(col(\"runtime\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"runtime\") == 0).count()\n",
    "\n",
    "print(f\"runtime: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e512abcf-6b04-422c-a28d-502064f59ddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast runtime to integer\n",
    "df = df.withColumn(\"runtime\", col(\"runtime\").cast(\"integer\"))\n",
    "\n",
    "# Verify the schema after casting\n",
    "df.select(\"runtime\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d89b771-b247-46f6-abf4-33b1a5ca8347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check for negative runtime values\n",
    "negative_runtime_count = df.filter(col(\"runtime\") < 0).count()\n",
    "print(f\"Number of movies with negative runtime: {negative_runtime_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13082999-2077-414c-b3a8-80017ae2af6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\"runtime\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03ecda0d-29d7-4dda-af0c-8616fd6e1b00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Although some \"movies\" can indeed be shorter than a minute (for example, very old movies or ads), in order to clean up our dataset we will assume that movies with 0 value for runtime, actually have this column missing. We will set them to null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5bfa447-c21a-4684-a45c-7ca407ca5caa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count rows where runtime == 0 before replacing\n",
    "zero_runtime_count = df.filter(col(\"runtime\") == 0).count()\n",
    "print(f\"Rows with runtime = 0 before nulling: {zero_runtime_count}\")\n",
    "\n",
    "# Replace runtime == 0 with null\n",
    "df = df.withColumn(\n",
    "    \"runtime\",\n",
    "    when(col(\"runtime\") == 0, None).otherwise(col(\"runtime\"))\n",
    ")\n",
    "\n",
    "# Verify how many runtime nulls now (should include the replacements)\n",
    "null_runtime_count = df.filter(col(\"runtime\").isNull()).count()\n",
    "print(f\"Rows with runtime = null after replacement: {null_runtime_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a96291a5-58e0-404f-933b-896496de8d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "outliers check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28e12822-e122-4e4b-aeaf-dd4b91ed49ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Q1 and Q3 using approxQuantile\n",
    "q1, q3 = df.approxQuantile(\"runtime\", [0.25, 0.75], 0.01)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Calculate bounds\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Identify outliers\n",
    "outliers_runtime = df.filter((col(\"runtime\") < lower_bound) | (col(\"runtime\") > upper_bound))\n",
    "df_no_outliers = df.filter((col(\"runtime\") >= lower_bound) & (col(\"runtime\") <= upper_bound))\n",
    "\n",
    "# Display the number of outliers\n",
    "print(f\"Movies with outlier runtime values: {outliers_runtime.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "821d5d06-207f-4009-b456-73bc1d590ec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Whiskers plot to visualize typical runtime and outliers\n",
    "runtime_pd = df.select(\"runtime\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=runtime_pd['runtime'], color='skyblue')\n",
    "\n",
    "plt.title(\"Runtime Distribution with Outliers\", fontsize=16)\n",
    "plt.xlabel(\"Runtime (Minutes)\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b46bdb62-5dc7-4dcd-bd9d-bc02d511cc15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Without outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeeacf3e-1cb5-4842-9356-d422059d20e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "df_no_outliers_pd = df_no_outliers.select(\"runtime\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df_no_outliers_pd['runtime'], color='skyblue')\n",
    "\n",
    "plt.title(\"Runtime Distribution without Outliers\", fontsize=16)\n",
    "plt.xlabel(\"Runtime (Minutes)\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08984de3-1a00-4128-8bbc-ccc409b1427f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ADULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d7ef4fb-a4e4-4d13-b2df-0136b116bb28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check distinct values in the \"adult\" column and count their occurrences\n",
    "distinct_adult = df.groupBy(\"adult\").count()\n",
    "\n",
    "# Get the number of distinct values in the \"adult\" column\n",
    "distinct_adult_count = distinct_adult.count()\n",
    "print(f\"Number of distinct values in 'adult': {distinct_adult_count}\")\n",
    "\n",
    "# Display the distinct values along with their counts\n",
    "display(distinct_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3681f9ef-e4ab-471e-9f7e-0de8fefe17b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot distribution of 'adult' values\n",
    "\n",
    "# Count occurrences of each distinct value in 'adult' column\n",
    "adult_distribution = df.groupBy(\"adult\").count().toPandas()\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='adult', y='count', data=adult_distribution, palette='Set2')\n",
    "plt.title('Distribution of Adult Movies')\n",
    "plt.xlabel('Adult')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "324b51e1-e31f-4757-a808-e37da18039f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Overwhelming majority of the movies is **not** for adults only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a4bcf37-20d6-4f84-8073-d5c9853ba079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ORIGINAL LANGUAGE and ORIGINAL TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e57e907-73e1-4a2e-ae94-ecd28196eee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, \"None\"/\"none\", and zero counts for original_language and original_title\n",
    "for cname in [\"original_language\", \"original_title\"]:\n",
    "    nulls   = df.filter(col(cname).isNull()).count()\n",
    "    empties = df.filter((col(cname) == \"\") |(col(cname) == \" \")).count()\n",
    "    nones   = df.filter(col(cname).isin(\"None\", \"none\")).count()\n",
    "    zeros   = df.filter(col(cname) == \"0\").count()\n",
    "\n",
    "    print(\n",
    "        f\"{cname}: nulls={nulls}, \"\n",
    "        f\"empty strings={empties}, \"\n",
    "        f\"'None'/'none' strings={nones}, \"\n",
    "        f\"zero values={zeros}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd03c78d-e76b-4675-a88b-dad70fd1b377",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by original_language and count occurrences\n",
    "language_counts = df.groupBy(\"original_language\").count()\n",
    "\n",
    "# Sort and get the top 20 languages\n",
    "top_20_languages = language_counts.orderBy(col(\"count\").desc()).limit(20)\n",
    "\n",
    "# Show the count of movies in the top 20 languages\n",
    "top_20_languages.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "babe351d-1a35-484f-80a4-f0be6df8fa88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by original_language and count occurrences\n",
    "language_counts = df.groupBy(\"original_language\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# Show top 5 languages by count\n",
    "top_languages = language_counts.limit(10).toPandas()\n",
    "\n",
    "# Plot top 5 languages\n",
    "plt.figure(figsize=(15, 9))\n",
    "sns.barplot(x=\"count\", y=\"original_language\", data=top_languages, palette=\"Set2\")\n",
    "plt.title('Top 10 Most Popular Languages')\n",
    "plt.xlabel('Number of Movies')\n",
    "plt.ylabel('Language')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f85384-e6a3-4775-8656-99f485bbfb62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Great majority of the movies was filmed in english as the original language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "057c3e55-928e-49d1-ac89-fc258ada2684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the total number of rows\n",
    "total_rows = df.count()\n",
    "\n",
    "# Count the number of rows where the original_title is different from title\n",
    "different_titles_count = df.filter(col(\"original_title\") != col(\"title\")).count()\n",
    "\n",
    "# Calculate the percentage of rows where original_title is different from title\n",
    "percentage_different_titles = (different_titles_count / total_rows) * 100\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Number of movies with different 'original_title' than 'title': {different_titles_count}\")\n",
    "print(f\"Percentage of movies with different titles: {percentage_different_titles:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3f38a9-6267-4496-b72d-04ea2e5e8368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by original_language and calculate the average revenue\n",
    "language_revenue_avg = df.groupBy(\"original_language\") \\\n",
    "    .agg(F.avg(\"revenue\").alias(\"average_revenue\"))\n",
    "\n",
    "# Sort the languages by average revenue in descending order\n",
    "language_revenue_avg = language_revenue_avg.orderBy(col(\"average_revenue\").desc()).limit(5)\n",
    "\n",
    "# Convert to Pandas for visualization\n",
    "language_revenue_avg_pd = language_revenue_avg.toPandas()\n",
    "\n",
    "# 4) Create a pretty bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=\"average_revenue\", \n",
    "    y=\"original_language\", \n",
    "    data=language_revenue_avg_pd, \n",
    "    palette=\"viridis\"  # Color palette\n",
    ")\n",
    "\n",
    "# Add titles and labels for clarity\n",
    "plt.title('Top 5 Original Languages by Average Revenue', fontsize=16)\n",
    "plt.xlabel('Average Revenue', fontsize=12)\n",
    "plt.ylabel('Original Language', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77e3f73c-f8cb-4271-8e86-c2bfba9eda6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The listed short forms of languages refer to:\n",
    "- **tn**: Tswana\n",
    "- **zh**: Chinese\n",
    "- **ko**: Korean\n",
    "- **hi**: Hindi\n",
    "\n",
    "https://www.science.co.il/language/Codes.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334787ee-cdab-4d5d-9d5e-7f7d8f8a3f96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1ff2092-b4eb-4cf4-a70d-7caf1fdec361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, \"None\"/\"none\", and zero counts for 'overview' column\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"overview\").isNull()).count()\n",
    "empties = df.filter((col(\"overview\") == \"\") | (col(\"overview\") == \" \")).count()\n",
    "nones   = df.filter(col(\"overview\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"overview\") == \"0\").count()\n",
    "\n",
    "print(f\"overview: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aefe88a8-a00d-4075-aac0-67df30cbc98e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set those empty or whitespace-only overviews to null\n",
    "df = df.withColumn(\n",
    "    \"overview\",\n",
    "    when(trim(col(\"overview\")) == \"\", None).otherwise(col(\"overview\"))\n",
    ")\n",
    "\n",
    "# Then check again how many empty strings there are\n",
    "empties = df.filter((col(\"overview\") == \"\") |(col(\"overview\") == \" \")).count()\n",
    "print(f\"Number of empty strings left: {empties}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe3fa9b9-4821-415d-ab3c-d38580ccaba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a column with the length of each overview\n",
    "df_length = df.withColumn(\"overview_length\", length(col(\"overview\")))\n",
    "\n",
    "# Compute min, max, avg, and median of overview_length\n",
    "stats = (\n",
    "    df_length\n",
    "    .agg(\n",
    "        F.min(\"overview_length\").alias(\"min_length\"),\n",
    "        F.max(\"overview_length\").alias(\"max_length\"),\n",
    "        F.avg(\"overview_length\").alias(\"avg_length\"),\n",
    "        F.expr(\"percentile_approx(overview_length, 0.5)\").alias(\"median_length\")\n",
    "    )\n",
    "    .collect()[0]\n",
    ")\n",
    "\n",
    "min_length    = stats[\"min_length\"]\n",
    "max_length    = stats[\"max_length\"]\n",
    "avg_length    = stats[\"avg_length\"]\n",
    "median_length = stats[\"median_length\"]\n",
    "\n",
    "print(f\"Shortest overview length: {min_length}\")\n",
    "print(f\"Longest overview length : {max_length}\")\n",
    "print(f\"Average overview length : {avg_length:.1f}\")\n",
    "print(f\"Median overview length  : {median_length}\")\n",
    "\n",
    "# Show examples of the shortest and longest overviews\n",
    "print(\"Examples of shortest overviews:\")\n",
    "display(\n",
    "    df_length\n",
    "      .filter(col(\"overview_length\") == min_length)\n",
    "      .select(\"id\", \"title\", \"overview\", \"overview_length\")\n",
    "      .limit(5)\n",
    ")\n",
    "\n",
    "print(\"Examples of longest overviews:\")\n",
    "display(\n",
    "    df_length\n",
    "      .filter(col(\"overview_length\") == max_length)\n",
    "      .select(\"id\", \"title\", \"overview\", \"overview_length\")\n",
    "      .limit(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684c1b28-6632-4c97-90e1-d533c23da79b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of overview lengths\n",
    "overview_lengths_pd = df_length.select(\"overview_length\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(overview_lengths_pd[\"overview_length\"], bins=50, kde=False)\n",
    "plt.title(\"Distribution of Overview Lengths\")\n",
    "plt.xlabel(\"Overview Length (characters)\")\n",
    "plt.ylabel(\"Number of Movies\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4076f957-9f02-40f7-acc3-2fd6c8fcf790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Distribution of overview leghts is right skewed. It indicates that most overviews have around 150 words. Only some have the maximum number of 1000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6d5d32e-95fa-4b67-94c5-291f10dad542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"overview_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "822db7ad-9d22-4a21-a3cf-93002b771310",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## POPULARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62cfab5d-4304-4173-b411-3e4210ed7c61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, \"None\"/\"none\", and zero counts for 'popularity' column\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"popularity\").isNull()).count()\n",
    "empties = df.filter((col(\"popularity\") == \"\") |(col(\"popularity\") == \" \")).count()\n",
    "nones   = df.filter(col(\"popularity\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"popularity\") == \"0\").count()\n",
    "\n",
    "print(f\"popularity: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cdedd71-d94c-46f0-81c4-512542ea7208",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast the datatype of popularity to double\n",
    "df = df.withColumn(\"popularity\", col(\"popularity\").cast(\"double\"))\n",
    "\n",
    "# Print the schema to check if it worked\n",
    "df.select(\"popularity\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6080c51a-eaa2-4432-badd-e9c234b3927f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Can **popularity** be zero? Let's display some examples of rows with **popularity** = 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23a2606d-6fe0-414f-9c6b-280274d3f91d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count how many movies have popularity == 0\n",
    "zero_pop_count = df.filter(col(\"popularity\") == 0).count()\n",
    "print(f\"Number of movies with popularity = 0: {zero_pop_count}\")\n",
    "\n",
    "# Display some examples of movies with popularity == 0 \n",
    "display(\n",
    "    df\n",
    "    .filter(col(\"popularity\") == 0)\n",
    "    .limit(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45d062bd-7622-47b2-b750-e84fd64ea8c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate summary statistics for popularity\n",
    "stats = df.agg(\n",
    "    F.min(\"popularity\").alias(\"min_popularity\"),\n",
    "    F.expr(\"percentile_approx(popularity, 0.5)\").alias(\"median_popularity\"),\n",
    "    F.avg(\"popularity\").alias(\"average_popularity\"),\n",
    "    F.max(\"popularity\").alias(\"max_popularity\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Min popularity     : {stats['min_popularity']}\")\n",
    "print(f\"Median popularity  : {stats['median_popularity']}\")\n",
    "print(f\"Average popularity : {stats['average_popularity']:.2f}\")\n",
    "print(f\"Max popularity     : {stats['max_popularity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "678013ac-7896-4ed4-9afd-be300369236e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18c923d9-d1b8-448e-8c1b-fb27e2fbb43a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter Spark DataFrame\n",
    "pop_filtered = df.filter(df['popularity'] > 0)\n",
    "\n",
    "# Convert to Pandas\n",
    "pop_filtered_pd = pop_filtered.select('popularity').toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(pop_filtered_pd['popularity'], kde=True, color='skyblue', bins=30)\n",
    "\n",
    "plt.xlim(0, 300)\n",
    "plt.title(\"Distribution of Popularity\", fontsize=16)\n",
    "plt.xlabel(\"Popularity\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f8e112-1a28-4748-ade4-9b3dbe5eeb22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## TAGLINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09776760-9c4f-4354-8313-ab1f51792489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The column **tagline** has the correct data type - string. Let's investigate this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4e578e6-00af-437c-a2a8-b23549b7365c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary for 'tagline'\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"tagline\").isNull()).count()\n",
    "empties = df.filter((col(\"tagline\") == \"\") | (col(\"tagline\") == \" \")).count()\n",
    "nones   = df.filter(col(\"tagline\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"tagline\") == \"0\").count()\n",
    "\n",
    "print(f\"tagline: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6baf6be5-a46a-4d9b-a9d0-e0989d4a3c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace \"None\"/\"none\" in `tagline` with null\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Count before replacement\n",
    "none_count = df.filter(col(\"tagline\").isin(\"None\", \"none\")).count()\n",
    "print(f\"Taglines with 'None' or 'none' before cleanup: {none_count}\")\n",
    "\n",
    "# Perform replacement\n",
    "df = df.withColumn(\n",
    "    \"tagline\",\n",
    "    when(col(\"tagline\").isin(\"None\", \"none\"), None).otherwise(col(\"tagline\"))\n",
    ")\n",
    "\n",
    "# Verify post-replacement\n",
    "post_none_count = df.filter(col(\"tagline\").isNull()).count()\n",
    "print(f\"Taglines null after cleanup: {post_none_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba82c706-6ed6-4d28-95d4-866de0921bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute min, max, average, and median lengths of `tagline`\n",
    "from pyspark.sql.functions import length, avg, expr, min as spark_min, max as spark_max\n",
    "\n",
    "df_length = df.withColumn(\"tagline_length\", length(col(\"tagline\")))\n",
    "\n",
    "stats = df_length.agg(\n",
    "    spark_min(\"tagline_length\").alias(\"min_length\"),\n",
    "    spark_max(\"tagline_length\").alias(\"max_length\"),\n",
    "    avg(\"tagline_length\").alias(\"avg_length\"),\n",
    "    expr(\"percentile_approx(tagline_length, 0.5)\").alias(\"median_length\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Shortest tagline: {stats['min_length']}\")\n",
    "print(f\"Longest  tagline: {stats['max_length']}\")\n",
    "print(f\"Average  tagline: {stats['avg_length']:.1f}\")\n",
    "print(f\"Median   tagline: {stats['median_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af1605cd-2874-4ba0-90a4-a402a3165f2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot distribution of tagline lengths\n",
    "# Convert to Pandas\n",
    "lengths_pd = df_length.select(\"tagline_length\").toPandas()[\"tagline_length\"].dropna()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(lengths_pd, bins=50, kde=False)\n",
    "plt.title(\"Distribution of Tagline Lengths\")\n",
    "plt.xlabel(\"Tagline Length (chars)\")\n",
    "plt.ylabel(\"Number of Movies\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29634aae-70c6-47c7-abf8-58bc2d810764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare average revenue: tagline NULL vs non-NULL\n",
    "# Compute stats\n",
    "rev_stats = (\n",
    "    df.groupBy(col(\"tagline\").isNull().alias(\"tagline_null\"))\n",
    "      .agg(\n",
    "          F.avg(\"revenue\").alias(\"avg_revenue\"),\n",
    "          F.expr(\"percentile_approx(revenue, 0.5)\").alias(\"median_revenue\")\n",
    "      )\n",
    "      .orderBy(\"tagline_null\")\n",
    "      .toPandas()\n",
    ")\n",
    "\n",
    "# Map boolean to labels\n",
    "rev_stats[\"tagline_null\"] = rev_stats[\"tagline_null\"].map({True: \"Null Tagline\", False: \"Has Tagline\"})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=\"tagline_null\", y=\"avg_revenue\", data=rev_stats, color=\"skyblue\", label=\"Average Revenue\", ci=None)\n",
    "sns.barplot(x=\"tagline_null\", y=\"median_revenue\", data=rev_stats, color=\"orange\", label=\"Median Revenue\", ci=None)\n",
    "plt.title(\"Revenue by Tagline Presence\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f0e7f3c-b314-4f92-a9a0-1fadce556cf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## GENRES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "559d4f41-9561-42a6-be62-ab64842677f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Currently **genres** is in type string. We want to cast it to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6b8d81c-d514-4724-80c7-595724df70fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary for 'genres'\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"genres\").isNull()).count()\n",
    "empties = df.filter((col(\"genres\") == \"\") | (col(\"genres\") == \" \")).count()\n",
    "nones   = df.filter(col(\"genres\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"genres\") == \"0\").count()\n",
    "\n",
    "print(f\"genres: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf596c48-c712-4356-9ee4-b86dd970a6f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast \"genres\" from string to array<string> (split on \", \")\n",
    "df = df.withColumn(\"genres_array\", split(col(\"genres\"), \",\\\\s*\"))\n",
    "df.select(\"genres\", \"genres_array\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c598ea28-4ffe-46bd-b29e-85ebc143bb6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count occurrences of each distinct genre\n",
    "genre_counts = (\n",
    "    df\n",
    "    .select(explode(col(\"genres_array\")).alias(\"genre\"))\n",
    "    .groupBy(\"genre\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "\n",
    "display(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55b51048-407a-4396-aecc-79c040826d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot top 5 genres by total revenue\n",
    "\n",
    "top5_revenue = (\n",
    "    df\n",
    "    .select(col(\"revenue\"), explode(col(\"genres_array\")).alias(\"genre\"))\n",
    "    .groupBy(\"genre\")\n",
    "    .agg(spark_sum(\"revenue\").alias(\"total_revenue\"))\n",
    "    .orderBy(col(\"total_revenue\").desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=\"total_revenue\",\n",
    "    y=\"genre\",\n",
    "    data=top5_revenue,\n",
    "    palette=\"Blues_d\"\n",
    ")\n",
    "plt.title(\"Top 5 Genres by Total Revenue\")\n",
    "plt.xlabel(\"Total Revenue\")\n",
    "plt.ylabel(\"Genre\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d89d0f-c94f-455f-88f0-6b2749abb514",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot top 5 genres by total budget\n",
    "top5_budget = (\n",
    "    df\n",
    "    .select(col(\"budget\"), explode(col(\"genres_array\")).alias(\"genre\"))\n",
    "    .groupBy(\"genre\")\n",
    "    .agg(spark_sum(\"budget\").alias(\"total_budget\"))\n",
    "    .orderBy(col(\"total_budget\").desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=\"total_budget\",\n",
    "    y=\"genre\",\n",
    "    data=top5_budget,\n",
    "    palette=\"Greens_d\"\n",
    ")\n",
    "plt.title(\"Top 5 Genres by Total Budget\")\n",
    "plt.xlabel(\"Total Budget\")\n",
    "plt.ylabel(\"Genre\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e44fa1fc-20f9-4206-be93-cb19ae68256e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Overwrite \"genres\" with the array column\n",
    "df = df.withColumn(\"genres\", col(\"genres_array\"))\n",
    "\n",
    "# Drop the helper \"genres_array\" column\n",
    "df = df.drop(\"genres_array\")\n",
    "\n",
    "# Verify the change\n",
    "df.select(\"genres\").printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2194d8d2-6c8e-4ecd-831a-25bafc1e3875",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split comma-separated string into an array\n",
    "df_split = df.withColumn(\"genre\", split(col(\"genres\"), \",\"))\n",
    "\n",
    "# Explode the array to separate rows\n",
    "df_exploded = df_split.withColumn(\"genre\", explode(col(\"genre\")))\n",
    "\n",
    "# Clean up whitespace (optional but helpful)\n",
    "df_clean = df_exploded.withColumn(\"genre\", trim(col(\"genre\")))\n",
    "\n",
    "# Group by genre and count\n",
    "genre_counts = df_clean.groupBy(\"genre\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "# Show the results\n",
    "display(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb87f5bf-7bdb-49fe-83f7-b18f81fdca60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7314f9ad-6e52-4260-8458-d6c7e9834c7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PRODUCTION COMPANIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d34a2bd2-ae80-426c-a51b-30a74c5be17a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Currently **production_companies** is in type string. We want to cast it to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8399fa31-e4eb-469f-9a6f-97095c9afa8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary for 'production_companies'\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"production_companies\").isNull()).count()\n",
    "empties = df.filter((col(\"production_companies\") == \"\") | (col(\"production_companies\") == \" \")).count()\n",
    "nones   = df.filter(col(\"production_companies\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"production_companies\") == \"0\").count()\n",
    "\n",
    "print(f\"production_companies: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1330949e-d362-4ef7-847c-cd1d97e6bc1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast `production_companies` from string to array<string>\n",
    "df = df.withColumn(\n",
    "    \"production_companies\",\n",
    "    split(col(\"production_companies\"), \",\\\\s*\")\n",
    ")\n",
    "df.select(\"production_companies\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651a5d0c-d93a-4d37-9cfa-ead341c96b40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 10 production_companies by number of movies\n",
    "company_counts = (\n",
    "    df\n",
    "    .select(explode(col(\"production_companies\")).alias(\"company\"))\n",
    "    .groupBy(\"company\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"count\", y=\"company\", data=company_counts, palette=\"Greens_d\")\n",
    "plt.title(\"Top 10 Production Companies by Number of Movies\")\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Company\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ac3ba2c-f2ad-47bb-8058-07bbe942c19e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3) Top 10 production_companies by average revenue\n",
    "\n",
    "company_revenue = (\n",
    "    df\n",
    "    .select(col(\"revenue\"), explode(col(\"production_companies\")).alias(\"company\"))\n",
    "    .groupBy(\"company\")\n",
    "    .agg(avg(\"revenue\").alias(\"avg_revenue\"))\n",
    "    .orderBy(col(\"avg_revenue\").desc())\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"avg_revenue\", y=\"company\", data=company_revenue, palette=\"Oranges_d\")\n",
    "plt.title(\"Top 10 Production Companies by Average Revenue\")\n",
    "plt.xlabel(\"Average Revenue\")\n",
    "plt.ylabel(\"Company\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27bed46f-142b-4565-97dc-de5568d4f432",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PRODUCTION COUNTRIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3fab533-30f7-4fc1-98bd-23bad9bfc0de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Currently **production_countries** is in type string. We want to cast it to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f3f6b59-c0e3-4ae2-83d8-328f6fc408c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary for 'production_countries'\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"production_countries\").isNull()).count()\n",
    "empties = df.filter((col(\"production_countries\") == \"\") | (col(\"production_countries\") == \" \")).count()\n",
    "nones   = df.filter(col(\"production_countries\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"production_countries\") == \"0\").count()\n",
    "\n",
    "print(f\"production_countries: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66425e6b-42a0-480e-a474-561d6ae1d4bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast `production_countries` from string to array<string>\n",
    "df = df.withColumn(\n",
    "    \"production_countries\",\n",
    "    split(col(\"production_countries\"), \",\\\\s*\")\n",
    ")\n",
    "df.select(\"production_countries\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18caa98a-7bb6-4fe4-af62-8cbc0e8aea62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 5 production_countries by number of movies\n",
    "\n",
    "country_counts = (\n",
    "    df\n",
    "    .select(explode(col(\"production_countries\")).alias(\"country\"))\n",
    "    .groupBy(\"country\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"count\", y=\"country\", data=country_counts, palette=\"Blues_d\")\n",
    "plt.title(\"Top 5 Production Countries by Number of Movies\")\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "061a7b79-6f69-47c0-8be0-55653938f918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SPOKEN LANGUAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3320c99c-53dc-471e-bb00-a2bbdc2cb2d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Currently **spoken_languages** is in type string. We want to cast it to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bec7d86a-3b88-4e6b-943d-68b4ed087892",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary for 'spoken_languages'\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"spoken_languages\").isNull()).count()\n",
    "empties = df.filter((col(\"spoken_languages\") == \"\") | (col(\"spoken_languages\") == \" \")).count()\n",
    "nones   = df.filter(col(\"spoken_languages\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"spoken_languages\") == \"0\").count()\n",
    "\n",
    "print(f\"spoken_languages: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7914d9d3-cc7a-4e96-918c-c56606cfa094",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast `spoken_languages` from string to array<string>\n",
    "df = df.withColumn(\n",
    "    \"spoken_languages\",\n",
    "    split(col(\"spoken_languages\"), \",\\\\s*\")\n",
    ")\n",
    "df.select(\"spoken_languages\").printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15c68d1-1341-4435-b34f-09e6783cb9ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 5 spoken_languages by number of movies\n",
    "lang_counts = (\n",
    "    df\n",
    "    .select(explode(col(\"spoken_languages\")).alias(\"language\"))\n",
    "    .groupBy(\"language\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"count\", y=\"language\", data=lang_counts, palette=\"Purples_d\")\n",
    "plt.title(\"Top 5 Spoken Languages by Number of Movies\")\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Language\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f792c2d5-f0ca-431e-a5b5-cd5df1d1cf5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Average revenue per top 5 spoken_languages\n",
    "top5_langs = lang_counts[\"language\"].tolist()\n",
    "avg_rev_lang = (\n",
    "    df\n",
    "    .select(col(\"revenue\"), explode(col(\"spoken_languages\")).alias(\"language\"))\n",
    "    .filter(col(\"language\").isin(top5_langs))\n",
    "    .groupBy(\"language\")\n",
    "    .agg(avg(\"revenue\").alias(\"avg_revenue\"))\n",
    "    .orderBy(col(\"avg_revenue\").desc())\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"avg_revenue\", y=\"language\", data=avg_rev_lang, palette=\"Purples_d\")\n",
    "plt.title(\"Average Revenue by Top 5 Spoken Languages\")\n",
    "plt.xlabel(\"Average Revenue\")\n",
    "plt.ylabel(\"Language\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9224736-da91-47ec-8e13-a4b1900fd160",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## KEYWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e141a42-c515-4f2c-845a-2e6adfe70539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Currently **keywords** is in type string. We want to cast it to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e65a135-dfaf-468f-b8d2-7cd132505846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary for 'keywords'\n",
    "total = df.count()\n",
    "\n",
    "nulls   = df.filter(col(\"keywords\").isNull()).count()\n",
    "empties = df.filter((col(\"keywords\") == \"\") | (col(\"keywords\") == \" \")).count()\n",
    "nones   = df.filter(col(\"keywords\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df.filter(col(\"keywords\") == \"0\").count()\n",
    "\n",
    "print(f\"keywords: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5aebb46-689a-42ae-a37d-5f7f06b0e872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast `keywords` from string to array<string>\n",
    "df = df.withColumn(\n",
    "    \"keywords\",\n",
    "    split(col(\"keywords\"), \",\\\\s*\")\n",
    ")\n",
    "df.select(\"keywords\").printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3e6347b-7e47-4cbf-a718-7d39bbf3304d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 50 keywords by frequency\n",
    "\n",
    "keyword_counts = (\n",
    "    df\n",
    "    .select(explode(col(\"keywords\")).alias(\"keyword\"))\n",
    "    .groupBy(\"keyword\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(50)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "print(\"Top 50 Keywords by Frequency:\")\n",
    "display(keyword_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be74938e-d43c-4aac-87b4-37c732f3ed3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Average revenue per top 10 keywords\n",
    "top10_keywords = keyword_counts[\"keyword\"].tolist()[:10]\n",
    "avg_rev_kw = (\n",
    "    df\n",
    "    .select(col(\"revenue\"), explode(col(\"keywords\")).alias(\"keyword\"))\n",
    "    .filter(col(\"keyword\").isin(top10_keywords))\n",
    "    .groupBy(\"keyword\")\n",
    "    .agg(avg(\"revenue\").alias(\"avg_revenue\"))\n",
    "    .orderBy(col(\"avg_revenue\").desc())\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"avg_revenue\", y=\"keyword\", data=avg_rev_kw, palette=\"Reds_d\")\n",
    "plt.title(\"Average Revenue by Top 10 Keywords\")\n",
    "plt.xlabel(\"Average Revenue\")\n",
    "plt.ylabel(\"Keyword\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953a7fd8-d93a-4474-8f43-08a4939bd7c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Create Profit and ROI to enhance our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "610d7f44-dd7d-4e01-9692-1613111371d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter out rows with zero or null budget or revenue to avoid division errors\n",
    "df_money = df.filter((col(\"budget\") > 0) & (col(\"revenue\") > 0))\n",
    "\n",
    "# Create 'profit' and 'roi' columns\n",
    "df_money = df_money.withColumn(\"profit\", col(\"revenue\") - col(\"budget\"))\n",
    "df_money = df_money.withColumn(\"roi\", col(\"revenue\") / col(\"budget\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f9a76c-3015-4271-b46b-33d7a80424ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Describe the statistics for 'profit' and 'roi' columns in PySpark\n",
    "df_money.describe(['profit', 'roi']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "699178aa-78dd-4514-9ba3-8af119579e41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Check only de ROI > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c10d0b-0642-431e-afe8-5f1f633cfa73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Calculate profit and ROI\n",
    "df_money = df.withColumn(\"profit\", col(\"revenue\") - col(\"budget\"))\n",
    "df_money = df_money.withColumn(\"roi\", col(\"revenue\") / col(\"budget\"))\n",
    "\n",
    "# Step 2: Filter for positive profit and ROI\n",
    "profit_roi_filtered = df_money.filter((col('profit') > 0) & (col('roi') > 0))\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame for plotting\n",
    "profit_roi_filtered_pd = profit_roi_filtered.select('profit').toPandas()\n",
    "\n",
    "# Step 4: Plot the distribution of profit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(profit_roi_filtered_pd['profit'], bins=100, color='mediumseagreen')\n",
    "plt.title('Distribution of Movie Profit')\n",
    "plt.xlabel('Profit (Revenue - Budget)')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.axvline(0, color='red', linestyle='--', label='Break-even')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "605769ce-9ab9-4d58-a3d9-f63375605d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Movies with the highest profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03c13e77-c864-4fea-bedf-c1993cee6501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Sort by profit in descending order and get the top 10 movies\n",
    "top_profit = profit_roi_filtered.orderBy(col('profit'), ascending=False).limit(10)\n",
    "\n",
    "# Step 2: Select the relevant columns (title, revenue, budget, profit)\n",
    "top_profit_selected = top_profit.select('title', 'revenue', 'budget', 'profit')\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame to display in a table\n",
    "top_profit_selected_pd = top_profit_selected.toPandas()\n",
    "\n",
    "# Step 4: Display the result\n",
    "print(top_profit_selected_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbd94cef-01b9-40d2-9b29-8c0cd8816da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Movies with the highest ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecdb3df0-befb-401e-8b45-9eddc38d0651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Sort by ROI in descending order and get the top 10 movies\n",
    "top_roi = profit_roi_filtered.orderBy(col('roi'), ascending=False).limit(10)\n",
    "\n",
    "# Step 2: Select the relevant columns (title, budget, revenue, roi)\n",
    "top_roi_selected = top_roi.select('title', 'budget', 'revenue', 'roi')\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame to display in a table\n",
    "top_roi_selected_pd = top_roi_selected.toPandas()\n",
    "\n",
    "# Step 4: Display the result\n",
    "print(top_roi_selected_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4151750b-9a46-4ad1-9107-34f6431b1678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Correlation Matrix for Popularity, Vote_Count and Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93a7c208-8ead-4ded-b7eb-ec6ebe37b295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to pandas for correlation analysis\n",
    "df_pd = df.select('popularity', 'vote_count', 'revenue').toPandas()\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_popularity = df_pd.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation between Popularity, Vote Count, and Revenue:\")\n",
    "print(correlation_popularity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71213ff4-e068-4eac-b1dd-a3da65a48533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Vote count appears to have the strongest relationship with revenue.\n",
    "\n",
    "Both popularity and vote count are positively correlated with revenue, but the relationship with popularity is weaker compared to the relationship between vote count and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e847fb93-a83b-4e0d-9e55-ad9e29124fa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Export the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d08b5d-68dc-4bbf-8eb6-f9843f49b884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# coalesce to 1 file (optional), write with header\n",
    "df.coalesce(1) \\\n",
    "  .write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .csv(\"/FileStore/tables/IMDB_Cleaned\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BDA PROJECT",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}