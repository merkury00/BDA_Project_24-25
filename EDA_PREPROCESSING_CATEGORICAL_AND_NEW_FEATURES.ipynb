{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import (\n",
    "    when, countDistinct, count, avg,\n",
    "    split, explode, trim, lit, length,\n",
    "    current_date, row_number, regexp_replace,\n",
    "    to_date, coalesce, col, when,\n",
    "    year, month, dayofmonth, array_contains, min, max, year\n",
    ")\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2809075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read the data set with previous tranformations\n",
    "df = spark.read.parquet(\"/FileStore/tables/Imdb_Movie_Dataset-2.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows do we have\n",
    "total_rows = df.count()\n",
    "print(f\"Total rows in `df`: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc72f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the type of each feature\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e19231",
   "metadata": {},
   "source": [
    "%md\n",
    "## Categorical Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0dba70",
   "metadata": {},
   "source": [
    "%md\n",
    "All numerical variables have been analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c90ee",
   "metadata": {},
   "source": [
    "%md\n",
    "### TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe copy of the original DataFrame\n",
    "df_copy3 = df.select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46507997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null, empty, and \"None\"/\"none\" titles\n",
    "null_count = df_copy3.filter(col(\"title\").isNull()).count()\n",
    "empty_count = df_copy3.filter((col(\"title\") == \"\") | (col(\"title\") == \" \")).count()\n",
    "none_count = df_copy3.filter((col(\"title\") == \"None\") | (col(\"title\") == \"none\")).count()\n",
    "\n",
    "print(f\"Null titles: {null_count}\")\n",
    "print(f\"Empty titles: {empty_count}\")\n",
    "print(f\"None titles: {none_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title length distribution\n",
    "title_len_df = df_copy3.withColumn(\"title_length\", length(col(\"title\")))\n",
    "min_len = title_len_df.agg({\"title_length\": \"min\"}).collect()[0][0]\n",
    "max_len = title_len_df.agg({\"title_length\": \"max\"}).collect()[0][0]\n",
    "median_len = title_len_df.approxQuantile(\"title_length\", [0.5], 0.01)[0]\n",
    "print(f\"Title length — min: {min_len}, median: {median_len:.0f}, max: {max_len}\")\n",
    "\n",
    "# Show extremes\n",
    "print(\"Longest titles:\")\n",
    "display(\n",
    "    title_len_df\n",
    "    .orderBy(col(\"title_length\").desc())\n",
    "    .select(\"id\", \"title\", \"title_length\")\n",
    "    .limit(5)\n",
    ")\n",
    "print(\"Shortest non-empty titles:\")\n",
    "display(\n",
    "    title_len_df\n",
    "    .filter(col(\"title\").isNotNull() & (col(\"title\") != \"\"))\n",
    "    .orderBy(col(\"title_length\").asc())\n",
    "    .select(\"id\", \"title\", \"title_length\")\n",
    "    .limit(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfdfdc",
   "metadata": {},
   "source": [
    "%md\n",
    "`title` column does not have any missing values and is stored with the correct data type. However, we noticed that some movies have titles consisting of only a single character. While this is unusual, it is not impossible in the context of cinema. Therefore, we will investigate this further to understand how many such cases exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbc8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of films with just one character as title\n",
    "single_char_titles_count = df_copy3.filter(length(col(\"title\")) == 1).count()\n",
    "\n",
    "print(f\"Number of movies with single-character titles: {single_char_titles_count}\")\n",
    "\n",
    "# display them\n",
    "display(df_copy3.filter(length(col(\"title\")) == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fcde39",
   "metadata": {},
   "source": [
    "%md\n",
    "Although it may seem unusual for a film to have a single-character title, we have decided to keep these entries in our dataset. Despite their atypical titles, these films contain relevant information for most of our features and therefore remain valuable for our analysis.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27892db",
   "metadata": {},
   "source": [
    "%md\n",
    "### STATUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee12f5",
   "metadata": {},
   "source": [
    "%md\n",
    "Let's check for distinct values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count distinct non-null statuses\n",
    "distinct_status_count = df_copy3.filter(col(\"status\").isNotNull()).select(\"status\").distinct().count()\n",
    "print(f\"Number of distinct 'status' values (excluding nulls): {distinct_status_count}\")\n",
    "\n",
    "# Show frequency of each status\n",
    "status_counts = df_copy3.groupBy(\"status\").count().orderBy(col(\"count\").desc())\n",
    "print(\"Counts per status:\")\n",
    "display(status_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62283071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average and median revenue by status\n",
    "status_revenue_stats = (\n",
    "    df_copy3\n",
    "    .groupBy(\"status\")\n",
    "    .agg(\n",
    "        F.avg(\"revenue\").alias(\"average_revenue\"),\n",
    "        F.expr(\"percentile_approx(revenue, 0.5)\").alias(\"median_revenue\")\n",
    "    )\n",
    "    .orderBy(\"status\")\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display(status_revenue_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c50a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = df_copy3.count()\n",
    "non_released_count = df_copy3.filter(col(\"status\") != \"Released\").count()\n",
    "percentage = (non_released_count / total_count) * 100\n",
    "\n",
    "print(f\"Non-released movies: {non_released_count} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d04b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display them\n",
    "display(df_copy3.filter(col(\"status\") != \"Released\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097f859",
   "metadata": {},
   "source": [
    "%md\n",
    "These entries represent less than 1% of the dataset and contain incomplete or unreliable information for modeling. Since the goal is to analyze actual outcomes, we will retain only films with Released status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove these entries\n",
    "df_copy3 = df_copy3.filter(col(\"status\") == \"Released\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6de0e",
   "metadata": {},
   "source": [
    "%md\n",
    "Since at this point all the movies in our dataset are already released,  which was our objective from the beginning,  this column becomes completely unnecessary as it now contains only a single unique value. Therefore, we will remove it from our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1540f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the column status\n",
    "df_copy3 = df_copy3.drop(\"status\")\n",
    "\n",
    "# just to check\n",
    "df_copy3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495eebcf",
   "metadata": {},
   "source": [
    "%md\n",
    "### ADULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distinct values in the \"adult\" column and count their occurrences\n",
    "distinct_adult = df_copy3.groupBy(\"adult\").count()\n",
    "\n",
    "# Get the number of distinct values in the \"adult\" column\n",
    "distinct_adult_count = distinct_adult.count()\n",
    "print(f\"Number of distinct values in 'adult': {distinct_adult_count}\")\n",
    "\n",
    "# Display the distinct values along with their counts\n",
    "display(distinct_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of 'adult' values\n",
    "\n",
    "# Count occurrences of each distinct value in 'adult' column\n",
    "adult_distribution = df_copy3.groupBy(\"adult\").count().toPandas()\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='adult', y='count', data=adult_distribution, palette='Set2')\n",
    "plt.title('Distribution of Adult Movies')\n",
    "plt.xlabel('Adult')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1368183",
   "metadata": {},
   "source": [
    "%md\n",
    "Overwhelming majority of the movies is **not** for adults only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c03bb6",
   "metadata": {},
   "source": [
    "%md\n",
    "### ORIGINAL_LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04928fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, \"None\"/\"none\", and zero counts for original_language\n",
    "for cname in [\"original_language\"]:\n",
    "    nulls   = df_copy3.filter(col(cname).isNull()).count()\n",
    "    empties = df_copy3.filter((col(cname) == \"\") |(col(cname) == \" \")).count()\n",
    "    nones   = df_copy3.filter(col(cname).isin(\"None\", \"none\")).count()\n",
    "    zeros   = df_copy3.filter(col(cname) == \"0\").count()\n",
    "\n",
    "    print(\n",
    "        f\"{cname}: nulls={nulls}, \"\n",
    "        f\"empty strings={empties}, \"\n",
    "        f\"'None'/'none' strings={nones}, \"\n",
    "        f\"zero values={zeros}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of unique \"original_language\"\n",
    "unique_lang_count = df_copy3.select(\"original_language\").distinct().count()\n",
    "print(f\"Number of unique original_language: {unique_lang_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494322ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique \"original_language\" values and their counts\n",
    "df_copy3.groupBy(\"original_language\") \\\n",
    "  .count() \\\n",
    "  .orderBy(col(\"count\").desc()) \\\n",
    "  .show(90, False) # number of rows to display, turn off truncation to see full column values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f0211",
   "metadata": {},
   "source": [
    "%md\n",
    "The listed short forms of languages refer to:\n",
    "- **tn**: Tswana\n",
    "- **zh**: Chinese\n",
    "- **ko**: Korean\n",
    "- **hi**: Hindi\n",
    "\n",
    "https://www.science.co.il/language/Codes.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7464d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by original_language and count occurrences\n",
    "language_counts = df_copy3.groupBy(\"original_language\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# Show top 5 languages by count\n",
    "top_languages = language_counts.limit(10).toPandas()\n",
    "\n",
    "# Plot top 5 languages\n",
    "plt.figure(figsize=(15, 9))\n",
    "sns.barplot(x=\"count\", y=\"original_language\", data=top_languages, palette=\"Set2\")\n",
    "plt.title('Top 10 Most Popular Languages')\n",
    "plt.xlabel('Number of Movies')\n",
    "plt.ylabel('Language')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of English-language movies\n",
    "count_en = df_copy3.filter(col(\"original_language\") == \"en\").count()\n",
    "\n",
    "# Count the number of Spanish-language movies\n",
    "count_es = df_copy3.filter(col(\"original_language\") == \"es\").count()\n",
    "\n",
    "# Calculate the percentage of Spanish movies compared to English\n",
    "percentage_es_vs_en = (count_es / count_en) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Spanish-language movies represent {percentage_es_vs_en:.2f}% of English-language movies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30290d8b",
   "metadata": {},
   "source": [
    "%md\n",
    "Great majority of the movies was filmed in english as the original language. To reduce cardinality we will create a new column `en_bool`, where 1 will denote the original language was english and 0 for other original language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean (0/1) column 'en_bool' for whether original_language == 'en'\n",
    "df_copy3 = df_copy3.withColumn(\n",
    "    \"en_bool\",\n",
    "    when(col(\"original_language\") == \"en\", lit(1)).otherwise(lit(0))\n",
    ")\n",
    "\n",
    "# Verify\n",
    "df_copy3.select(\"original_language\", \"en_bool\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a181653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distribution of values in \"en_bool\"\n",
    "dist_df = df_copy3.groupBy(\"en_bool\").count().orderBy(\"en_bool\")\n",
    "\n",
    "# Show the distribution counts\n",
    "dist_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478a432",
   "metadata": {},
   "source": [
    "%md\n",
    "We now have a variable that shows good balance and strong relevance for our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas for plotting\n",
    "dist_pd = dist_df.toPandas()\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(dist_pd[\"en_bool\"].astype(str), dist_pd[\"count\"])\n",
    "plt.xlabel(\"en_bool (1 = English, 0 = Other)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of en_bool\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782030c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by original_language and calculate the average revenue\n",
    "language_revenue_avg = df_copy3.groupBy(\"original_language\") \\\n",
    "    .agg(F.avg(\"revenue\").alias(\"average_revenue\"))\n",
    "\n",
    "# Sort the languages by average revenue in descending order\n",
    "language_revenue_avg = language_revenue_avg.orderBy(col(\"average_revenue\").desc()).limit(5)\n",
    "\n",
    "# Convert to Pandas for visualization\n",
    "language_revenue_avg_pd = language_revenue_avg.toPandas()\n",
    "\n",
    "# 4) Create a pretty bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=\"average_revenue\", \n",
    "    y=\"original_language\", \n",
    "    data=language_revenue_avg_pd, \n",
    "    palette=\"viridis\"  # Color palette\n",
    ")\n",
    "\n",
    "# Add titles and labels for clarity\n",
    "plt.title('Top 5 Original Languages by Average Revenue', fontsize=16)\n",
    "plt.xlabel('Average Revenue', fontsize=12)\n",
    "plt.ylabel('Original Language', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71cfa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by en_bool and compute average revenue\n",
    "avg_rev_en = df_copy3.groupBy(\"en_bool\").agg(F.avg(\"revenue\").alias(\"average_revenue\"))\n",
    "\n",
    "# Convert to Pandas\n",
    "avg_rev_en_pd = avg_rev_en.toPandas()\n",
    "\n",
    "# Simple plot\n",
    "plt.bar(avg_rev_en_pd[\"en_bool\"].astype(str), avg_rev_en_pd[\"average_revenue\"])\n",
    "plt.xlabel(\"en_bool (1 = English, 0 = Other)\")\n",
    "plt.ylabel(\"Average Revenue\")\n",
    "plt.title(\"Average Revenue by en_bool\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56ef82",
   "metadata": {},
   "source": [
    "%md\n",
    "As expected, the majority of the movies are in English, which also explains the higher overall revenue associated with this language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4a1f6",
   "metadata": {},
   "source": [
    "%md\n",
    "### ORIGINAL_TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of rows\n",
    "total_rows = df_copy3.count()\n",
    "\n",
    "# Count the number of rows where the original_title is different from title\n",
    "different_titles_count = df_copy3.filter(col(\"original_title\") != col(\"title\")).count()\n",
    "\n",
    "# Calculate the percentage of rows where original_title is different from title\n",
    "percentage_different_titles = (different_titles_count / total_rows) * 100\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Number of movies with different 'original_title' than 'title': {different_titles_count}\")\n",
    "print(f\"Percentage of movies with different titles: {percentage_different_titles:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, \"None\"/\"none\", and zero counts for 'original_title' column\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"original_title\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"original_title\") == \"\") | (col(\"original_title\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"original_title\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"original_title\") == \"0\").count()\n",
    "\n",
    "print(f\"original_title: nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the length of each original_title\n",
    "df_length = df_copy3.withColumn(\"original_title_length\", length(col(\"original_title\")))\n",
    "\n",
    "# Compute min, max, avg, and median of original_title_length\n",
    "stats = (\n",
    "    df_length\n",
    "    .agg(\n",
    "        F.min(\"original_title_length\").alias(\"min_length\"),\n",
    "        F.max(\"original_title_length\").alias(\"max_length\"),\n",
    "        F.avg(\"original_title_length\").alias(\"avg_length\"),\n",
    "        F.expr(\"percentile_approx(original_title_length, 0.5)\").alias(\"median_length\")\n",
    "    )\n",
    "    .collect()[0]\n",
    ")\n",
    "\n",
    "min_length    = stats[\"min_length\"]\n",
    "max_length    = stats[\"max_length\"]\n",
    "avg_length    = stats[\"avg_length\"]\n",
    "median_length = stats[\"median_length\"]\n",
    "\n",
    "print(f\"Shortest original_title length: {min_length}\")\n",
    "print(f\"Longest original_title length : {max_length}\")\n",
    "print(f\"Average original_title length : {avg_length:.1f}\")\n",
    "print(f\"Median original_title length  : {median_length}\")\n",
    "\n",
    "# Show examples of the shortest and longest original_titles\n",
    "print(\"Examples of shortest original_titles:\")\n",
    "display(\n",
    "    df_length\n",
    "      .filter(col(\"original_title_length\") == min_length)\n",
    "      .select(\"id\", \"title\", \"original_title\", \"original_title_length\")\n",
    "      .limit(5)\n",
    ")\n",
    "\n",
    "print(\"Examples of longest original_titles:\")\n",
    "display(\n",
    "    df_length\n",
    "      .filter(col(\"original_title_length\") == max_length)\n",
    "      .select(\"id\", \"title\", \"original_title\", \"original_title_length\")\n",
    "      .limit(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c96b66",
   "metadata": {},
   "source": [
    "%md\n",
    "This category has too much diversity and will not add meaningful value to our model or to the main objective of this project. We will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab57475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy3 = df_copy3.drop(\"original_title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51770441",
   "metadata": {},
   "source": [
    "%md\n",
    "### OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of null, empty-string, \"None\"/\"none\", and zero counts for 'overview' column\n",
    "total = df_copy3.count()\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"overview\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"overview\") == \"\") | (col(\"overview\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"overview\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"overview\") == \"0\").count()\n",
    "\n",
    "print(f\"overview: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set those empty or whitespace-only overviews to null\n",
    "df_copy3 = df_copy3.withColumn(\n",
    "    \"overview\",\n",
    "    when(trim(col(\"overview\")) == \"\", None).otherwise(col(\"overview\"))\n",
    ")\n",
    "\n",
    "# Then check again how many empty strings there are\n",
    "empties = df_copy3.filter((col(\"overview\") == \"\") |(col(\"overview\") == \" \")).count()\n",
    "print(f\"Number of empty strings left: {empties}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3505e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the length of each overview\n",
    "df_length = df_copy3.withColumn(\"overview_length\", length(col(\"overview\")))\n",
    "\n",
    "# Compute min, max, avg, and median of overview_length\n",
    "stats = (\n",
    "    df_length\n",
    "    .agg(\n",
    "        F.min(\"overview_length\").alias(\"min_length\"),\n",
    "        F.max(\"overview_length\").alias(\"max_length\"),\n",
    "        F.avg(\"overview_length\").alias(\"avg_length\"),\n",
    "        F.expr(\"percentile_approx(overview_length, 0.5)\").alias(\"median_length\")\n",
    "    )\n",
    "    .collect()[0]\n",
    ")\n",
    "\n",
    "min_length    = stats[\"min_length\"]\n",
    "max_length    = stats[\"max_length\"]\n",
    "avg_length    = stats[\"avg_length\"]\n",
    "median_length = stats[\"median_length\"]\n",
    "\n",
    "print(f\"Shortest overview length: {min_length}\")\n",
    "print(f\"Longest overview length : {max_length}\")\n",
    "print(f\"Average overview length : {avg_length:.1f}\")\n",
    "print(f\"Median overview length  : {median_length}\")\n",
    "\n",
    "# Show examples of the shortest and longest overviews\n",
    "print(\"Examples of shortest overviews:\")\n",
    "display(\n",
    "    df_length\n",
    "      .filter(col(\"overview_length\") == min_length)\n",
    "      .select(\"id\", \"title\", \"overview\", \"overview_length\")\n",
    "      .limit(5)\n",
    ")\n",
    "\n",
    "print(\"Examples of longest overviews:\")\n",
    "display(\n",
    "    df_length\n",
    "      .filter(col(\"overview_length\") == max_length)\n",
    "      .select(\"id\", \"title\", \"overview\", \"overview_length\")\n",
    "      .limit(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of overview lengths\n",
    "overview_lengths_pd = df_length.select(\"overview_length\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(overview_lengths_pd[\"overview_length\"], bins=50, kde=False)\n",
    "plt.title(\"Distribution of Overview Lengths\")\n",
    "plt.xlabel(\"Overview Length (characters)\")\n",
    "plt.ylabel(\"Number of Movies\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0343ce8",
   "metadata": {},
   "source": [
    "%md\n",
    "Distribution of overview leghts is right skewed. It indicates that most overviews have around 150 words. Only some have the maximum number of 998 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy3 = df_copy3.drop(\"overview_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31eac64",
   "metadata": {},
   "source": [
    "%md\n",
    "### TAGLINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59c877",
   "metadata": {},
   "source": [
    "%md\n",
    "The column `tagline` has the correct data type - string. Let's investigate this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeafdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for 'tagline'\n",
    "total = df_copy3.count()\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"tagline\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"tagline\") == \"\") | (col(\"tagline\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"tagline\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"tagline\") == \"0\").count()\n",
    "\n",
    "print(f\"tagline: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"None\"/\"none\" in `tagline` with null\n",
    "\n",
    "# Count before replacement\n",
    "none_count = df.filter(col(\"tagline\").isin(\"None\", \"none\")).count()\n",
    "print(f\"Taglines with 'None' or 'none' before cleanup: {none_count}\")\n",
    "\n",
    "# Perform replacement\n",
    "df = df.withColumn(\n",
    "    \"tagline\",\n",
    "    when(col(\"tagline\").isin(\"None\", \"none\"), None).otherwise(col(\"tagline\"))\n",
    ")\n",
    "\n",
    "# Verify post-replacement\n",
    "post_none_count = df.filter(col(\"tagline\").isNull()).count()\n",
    "print(f\"Taglines null after cleanup: {post_none_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute min, max, average, and median lengths of `tagline`\n",
    "from pyspark.sql.functions import length, avg, expr, min as spark_min, max as spark_max\n",
    "\n",
    "df_length = df_copy3.withColumn(\"tagline_length\", length(col(\"tagline\")))\n",
    "\n",
    "stats = df_length.agg(\n",
    "    spark_min(\"tagline_length\").alias(\"min_length\"),\n",
    "    spark_max(\"tagline_length\").alias(\"max_length\"),\n",
    "    avg(\"tagline_length\").alias(\"avg_length\"),\n",
    "    expr(\"percentile_approx(tagline_length, 0.5)\").alias(\"median_length\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Shortest tagline: {stats['min_length']}\")\n",
    "print(f\"Longest  tagline: {stats['max_length']}\")\n",
    "print(f\"Average  tagline: {stats['avg_length']:.1f}\")\n",
    "print(f\"Median   tagline: {stats['median_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of tagline lengths\n",
    "# Convert to Pandas\n",
    "lengths_pd = df_length.select(\"tagline_length\").toPandas()[\"tagline_length\"].dropna()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(lengths_pd, bins=50, kde=False)\n",
    "plt.title(\"Distribution of Tagline Lengths\")\n",
    "plt.xlabel(\"Tagline Length (chars)\")\n",
    "plt.ylabel(\"Number of Movies\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare average revenue: tagline NULL vs non-NULL\n",
    "# Compute stats\n",
    "rev_stats = (\n",
    "    df.groupBy(col(\"tagline\").isNull().alias(\"tagline_null\"))\n",
    "      .agg(\n",
    "          F.avg(\"revenue\").alias(\"avg_revenue\"),\n",
    "          F.expr(\"percentile_approx(revenue, 0.5)\").alias(\"median_revenue\")\n",
    "      )\n",
    "      .orderBy(\"tagline_null\")\n",
    "      .toPandas()\n",
    ")\n",
    "\n",
    "# Map boolean to labels\n",
    "rev_stats[\"tagline_null\"] = rev_stats[\"tagline_null\"].map({True: \"Null Tagline\", False: \"Has Tagline\"})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=\"tagline_null\", y=\"avg_revenue\", data=rev_stats, color=\"skyblue\", label=\"Average Revenue\", ci=None)\n",
    "sns.barplot(x=\"tagline_null\", y=\"median_revenue\", data=rev_stats, color=\"orange\", label=\"Median Revenue\", ci=None)\n",
    "plt.title(\"Revenue by Tagline Presence\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720ea69",
   "metadata": {},
   "source": [
    "%md\n",
    "To reduce complexity of this variable we will create a boolean feature \"tagline_bool\", for which value 1 will denote that the tagline was present and 0 for null taglines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a374d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean column from \"tagline\" (0 if null, 1 if not)\n",
    "df_copy3 = df_copy3.withColumn(\n",
    "    \"tagline_bool\",\n",
    "    when(col(\"tagline\").isNull(), lit(0)).otherwise(lit(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show counts of tagline_bool values\n",
    "df_copy3.groupBy(\"tagline_bool\") \\\n",
    "  .count() \\\n",
    "  .orderBy(\"tagline_bool\") \\\n",
    "  .show()\n",
    "\n",
    "#  Convert to Pandas for plotting\n",
    "dist_pd = (\n",
    "    df_copy3.groupBy(\"tagline_bool\")\n",
    "      .count()\n",
    "      .orderBy(\"tagline_bool\")\n",
    "      .toPandas()\n",
    ")\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(dist_pd[\"tagline_bool\"].astype(str), dist_pd[\"count\"])\n",
    "plt.xlabel(\"tagline_bool (1 = has tagline, 0 = no tagline)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Tagline Presence\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6352fa",
   "metadata": {},
   "source": [
    "%md\n",
    "Now that the `tagline` feature has been converted to a boolean, it becomes useful for our predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46325af",
   "metadata": {},
   "source": [
    "%md\n",
    "### GENRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for 'genres'\n",
    "total = df_copy3.count()\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"genres\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"genres\") == \"\") | (col(\"genres\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"genres\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"genres\") == \"0\").count()\n",
    "\n",
    "print(f\"genres: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy3.select(\"genres\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec35e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each distinct genre\n",
    "# Split the comma-separated string into an array, trimming whitespace\n",
    "df_copy3 = df_copy3.withColumn(\n",
    "    \"genres_array\",\n",
    "    split(col(\"genres\"), \"\\\\s*,\\\\s*\")\n",
    ")\n",
    "\n",
    "# Explode the array so each genre gets its own row\n",
    "genres_exploded = df_copy3.select(\n",
    "    explode(col(\"genres_array\")).alias(\"genre\")\n",
    ")\n",
    "\n",
    "# Group by the individual genre values and count\n",
    "genres_exploded.groupBy(\"genre\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show(100, False)  # adjust the number 100 if you want more or fewer rows\n",
    "\n",
    "# Count the number of distinct genres\n",
    "distinct_genre_count = genres_exploded.select(\"genre\").distinct().count()\n",
    "print(f\"Number of distinct genres: {distinct_genre_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9824fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle \"genres\" for boolean columns\n",
    "# Explode into individual genres and plot top 10 by total revenue\n",
    "df_copy3 = df_copy3.withColumn(\n",
    "    \"genres_array\",\n",
    "    split(regexp_replace(col(\"genres\"), \"\\\\s*,\\\\s*\", \",\"), \",\")\n",
    ")\n",
    "\n",
    "genre_rev_df = (\n",
    "    df_copy3.select(explode(col(\"genres_array\")).alias(\"genre\"), col(\"revenue\"))\n",
    "      .groupBy(\"genre\")\n",
    "      .agg(spark_sum(\"revenue\").alias(\"total_revenue\"))\n",
    "      .orderBy(col(\"total_revenue\").desc())\n",
    ")\n",
    "\n",
    "genre_rev_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_genres = genre_rev_df.limit(10).toPandas()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(top10_genres[\"genre\"], top10_genres[\"total_revenue\"])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Top 10 Genres by Total Revenue\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Total Revenue\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca02e8",
   "metadata": {},
   "source": [
    "%md\n",
    "Here we can clearly observe that the genres contributing to higher movie revenue are Action, Adventure, Comedy, and Drama, standing out significantly from the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543d1ca",
   "metadata": {},
   "source": [
    "%md\n",
    "To simplify this variable and make it more usable, we will transform it into six possible boolean combinations based on the five most common genres. If none of these genres are present (i.e., all five are set to 0), the movie will be classified as belonging to one of the remaining, less frequent genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean columns for top 5 most profitable genres\n",
    "top5_genres = [row[\"genre\"] for row in genre_rev_df.limit(5).collect()]\n",
    "for g in top5_genres:\n",
    "    col_name = g.lower().replace(\" \", \"_\")\n",
    "    df_copy3 = df_copy3.withColumn(\n",
    "        col_name,\n",
    "        when(array_contains(col(\"genres_array\"), g), lit(1)).otherwise(lit(0))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41bf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover the list of boolean columns\n",
    "bool_cols   = [g.lower().replace(\" \", \"_\") for g in top5_genres]\n",
    "\n",
    "# View the first 10 rows of those boolean columns\n",
    "print(\"Boolean columns for top 5 genres:\", bool_cols)\n",
    "df_copy3.select(bool_cols).show(10, False)\n",
    "\n",
    "# Count how many movies have each genre (sum of the 1s)\n",
    "counts_df = df_copy3.select([spark_sum(col(c)).alias(c) for c in bool_cols]) \\\n",
    "              .toPandas() \\\n",
    "              .melt(var_name=\"genre\", value_name=\"count\")\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(counts_df[\"genre\"], counts_df[\"count\"])\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Number of Movies\")\n",
    "plt.title(\"Distribution of Top 5 Genres\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa6f0a",
   "metadata": {},
   "source": [
    "%md\n",
    "From this chart, and based on what we already knew, we can see that the Adventure genre, although it is the least represented among the five most popular genres in our dataset, ends up having the second highest average revenue. This highlights its strong impact on box office performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8c6f3",
   "metadata": {},
   "source": [
    "%md\n",
    "### PRODUCTION_COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for 'production_companies'\n",
    "total = df_copy3.count()\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"production_companies\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"production_companies\") == \"\") | (col(\"production_companies\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"production_companies\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"production_companies\") == \"0\").count()\n",
    "\n",
    "print(f\"production_companies: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64414187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 production_companies by number of movies\n",
    "company_counts = (\n",
    "    df_copy3\n",
    "    .groupBy(\"production_companies\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"count\", y=\"production_companies\", data=company_counts, palette=\"Greens_d\")\n",
    "plt.title(\"Top 10 Production Companies by Number of Movies\")\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Company\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 production_companies by average revenue\n",
    "\n",
    "company_revenue = (\n",
    "    df_copy3\n",
    "    .groupBy(\"production_companies\")\n",
    "    .agg(avg(\"revenue\").alias(\"avg_revenue\"))\n",
    "    .orderBy(col(\"avg_revenue\").desc())\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"avg_revenue\", y=\"production_companies\", data=company_revenue, palette=\"Oranges_d\")\n",
    "plt.title(\"Top 10 Production Companies by Average Revenue\")\n",
    "plt.xlabel(\"Average Revenue\")\n",
    "plt.ylabel(\"Company\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18088006",
   "metadata": {},
   "source": [
    "%md\n",
    "From these two charts, it is easy to see that the number of films produced does not necessarily reflect quality or success. For example, Metro-Goldwyn-Mayer is the company with the highest number of productions, yet when looking at the top 10 production companies by revenue, it ranks only 10th. This highlights the discrepancy between quantity and profitability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a2175",
   "metadata": {},
   "source": [
    "%md\n",
    "There are many high-cardinality cells in `production_companies`. Therefore, we will create boolean columns, for the top 6 most profitable ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split & explode high‐cardinality “production_companies”\n",
    "df_copy3 = df_copy3.withColumn(\n",
    "    \"prod_companies_array\",\n",
    "    split(\n",
    "        regexp_replace(col(\"production_companies\"), r\"\\s*,\\s*\", \",\"),  # normalize commas\n",
    "        \",\"\n",
    "    )\n",
    ")\n",
    "prod_exploded = df_copy3.select(\n",
    "    explode(col(\"prod_companies_array\")).alias(\"company\"),\n",
    "    col(\"revenue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences & distinct count\n",
    "prod_counts = (\n",
    "    prod_exploded\n",
    "      .groupBy(\"company\")\n",
    "      .count()\n",
    "      .orderBy(col(\"count\").desc())\n",
    ")\n",
    "prod_counts.show(100, False)  # show top 100 by frequency\n",
    "print(f\"Number of distinct production companies: {prod_counts.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 companies by total revenue & plot\n",
    "prod_rev = (\n",
    "    prod_exploded\n",
    "      .groupBy(\"company\")\n",
    "      .agg(spark_sum(\"revenue\").alias(\"total_revenue\"))\n",
    "      .orderBy(col(\"total_revenue\").desc())\n",
    ")\n",
    "top10_prod = prod_rev.limit(10)\n",
    "top10_prod.show(10, False)\n",
    "\n",
    "# Plot\n",
    "pd_top10_prod = top10_prod.toPandas()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(pd_top10_prod[\"company\"], pd_top10_prod[\"total_revenue\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top 10 Production Companies by Total Revenue\")\n",
    "plt.xlabel(\"Production Company\")\n",
    "plt.ylabel(\"Total Revenue\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07553c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean flags for the top 6 most profitable companies\n",
    "top6_prod = [row[\"company\"] for row in prod_rev.limit(6).collect()]\n",
    "for comp in top6_prod:\n",
    "    flag_col = comp.lower().replace(\" \", \"_\").replace(\".\", \"\").replace(\",\", \"\")\n",
    "    df_copy3 = df_copy3.withColumn(\n",
    "        flag_col,\n",
    "        when(array_contains(col(\"prod_companies_array\"), comp), 1).otherwise(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb18cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of these boolean flags\n",
    "bool_cols_prod = [c.lower().replace(\" \", \"_\").replace(\".\", \"\").replace(\",\", \"\") for c in top6_prod]\n",
    "dist_prod = (\n",
    "    df_copy3\n",
    "      .select([spark_sum(col(c)).alias(c) for c in bool_cols_prod])\n",
    "      .toPandas()\n",
    "      .melt(var_name=\"company\", value_name=\"count\")\n",
    ")\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(dist_prod[\"company\"], dist_prod[\"count\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Distribution of Top 6 Production Company Flags\")\n",
    "plt.ylabel(\"Number of Movies\")\n",
    "plt.xlabel(\"Company Flag\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f3f7e",
   "metadata": {},
   "source": [
    "%md\n",
    "For this variable to become useful for our model, it also needs to be converted into a binary system of 6 categories, representing the top 5 production companies by revenue, plus one additional category for all others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e72b4c",
   "metadata": {},
   "source": [
    "%md\n",
    "### PRODUCTION_COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1501b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for 'production_countries'\n",
    "total = df_copy3.count()\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"production_countries\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"production_countries\") == \"\") | (col(\"production_countries\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"production_countries\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"production_countries\") == \"0\").count()\n",
    "\n",
    "print(f\"production_countries: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 production_countries by number of movies\n",
    "\n",
    "country_counts = (\n",
    "    df_copy3\n",
    "    .groupBy(\"production_countries\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"count\", y=\"production_countries\", data=country_counts, palette=\"Blues_d\")\n",
    "plt.title(\"Top 5 Production Countries by Number of Movies\")\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778c01c",
   "metadata": {},
   "source": [
    "%md\n",
    "It is easy to observe that the United States is the largest producer of films. To make this variable useful for our model, we will also convert it into a binary system of five categories, representing the top film-producing countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec7a7b",
   "metadata": {},
   "source": [
    "%md\n",
    "### SPOKEN_LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for 'spoken_languages'\n",
    "total = df_copy3.count()\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"spoken_languages\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"spoken_languages\") == \"\") | (col(\"spoken_languages\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"spoken_languages\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"spoken_languages\") == \"0\").count()\n",
    "\n",
    "print(f\"spoken_languages: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e484a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display distinct languages\n",
    "display(\n",
    "    df_copy3\n",
    "      .select(\"spoken_languages\")\n",
    "      .distinct()\n",
    "      .orderBy(\"spoken_languages\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 spoken_languages by number of movies\n",
    "lang_counts = (\n",
    "    df_copy3\n",
    "    .groupBy(\"spoken_languages\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"count\", y=\"spoken_languages\", data=lang_counts, palette=\"Purples_d\")\n",
    "plt.title(\"Top 5 Spoken Languages by Number of Movies\")\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Language\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d9388",
   "metadata": {},
   "source": [
    "%md\n",
    "For this variable as well, we will create a binary system with five elements, representing the four most frequent values along with one additional category for all remaining cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9a642",
   "metadata": {},
   "source": [
    "%md\n",
    "### KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for 'keywords'\n",
    "total = df_copy3.count()\n",
    "\n",
    "nulls   = df_copy3.filter(col(\"keywords\").isNull()).count()\n",
    "empties = df_copy3.filter((col(\"keywords\") == \"\") | (col(\"keywords\") == \" \")).count()\n",
    "nones   = df_copy3.filter(col(\"keywords\").isin(\"None\", \"none\")).count()\n",
    "zeros   = df_copy3.filter(col(\"keywords\") == \"0\").count()\n",
    "\n",
    "print(f\"keywords: total={total}, nulls={nulls}, empty strings={empties}, 'None'/'none' strings={nones}, zero values={zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split & explode “keywords”\n",
    "df_copy3 = df_copy3.withColumn(\n",
    "    \"keywords_array\",\n",
    "    split(\n",
    "        regexp_replace(col(\"keywords\"), r\"\\s*,\\s*\", \",\"), \n",
    "        \",\"\n",
    "    )\n",
    ")\n",
    "kw_exploded = df_copy3.select(\n",
    "    explode(col(\"keywords_array\")).alias(\"keyword\"),\n",
    "    col(\"revenue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences & distinct count\n",
    "kw_counts = (\n",
    "    kw_exploded\n",
    "      .groupBy(\"keyword\")\n",
    "      .count()\n",
    "      .orderBy(col(\"count\").desc())\n",
    ")\n",
    "kw_counts.show(100, False)\n",
    "print(f\"Number of distinct keywords: {kw_counts.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8249f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 keywords by total revenue & plot\n",
    "kw_rev = (\n",
    "    kw_exploded\n",
    "      .groupBy(\"keyword\")\n",
    "      .agg(spark_sum(\"revenue\").alias(\"total_revenue\"))\n",
    "      .orderBy(col(\"total_revenue\").desc())\n",
    ")\n",
    "top10_kw = kw_rev.limit(10)\n",
    "top10_kw.show(10, False)\n",
    "\n",
    "pd_top10_kw = top10_kw.toPandas()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(pd_top10_kw[\"keyword\"], pd_top10_kw[\"total_revenue\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top 10 Keywords by Total Revenue\")\n",
    "plt.xlabel(\"Keyword\")\n",
    "plt.ylabel(\"Total Revenue\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b94e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean flags for the top 3 most profitable keywords\n",
    "top3_kw = [row[\"keyword\"] for row in kw_rev.limit(3).collect()]\n",
    "for kw in top3_kw:\n",
    "    flag_col = kw.lower().replace(\" \", \"_\").replace(\".\", \"\").replace(\",\", \"\")\n",
    "    df_copy3 = df_copy3.withColumn(\n",
    "        flag_col,\n",
    "        when(array_contains(col(\"keywords_array\"), kw), 1).otherwise(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ff626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of these boolean keyword flags\n",
    "bool_cols_kw = [k.lower().replace(\" \", \"_\").replace(\".\", \"\").replace(\",\", \"\") for k in top3_kw]\n",
    "dist_kw = (\n",
    "    df_copy3\n",
    "      .select([spark_sum(col(c)).alias(c) for c in bool_cols_kw])\n",
    "      .toPandas()\n",
    "      .melt(var_name=\"keyword\", value_name=\"count\")\n",
    ")\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(dist_kw[\"keyword\"], dist_kw[\"count\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Distribution of Top 3 Keyword Flags\")\n",
    "plt.ylabel(\"Number of Movies\")\n",
    "plt.xlabel(\"Keyword Flag\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d392278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keywords' string column into individual rows.\n",
    "#    Adjust the delimiter in split() if your keywords are comma-separated, e.g. \",\" instead of \"\\\\|\"\n",
    "keywords_exploded = df.select(\n",
    "    explode(\n",
    "        split(col(\"keywords\"), \"\\\\|\")\n",
    "    ).alias(\"keyword\")\n",
    ").filter(col(\"keyword\") != \"\")\n",
    "\n",
    "# 2) Count and take the top 50\n",
    "top50 = (\n",
    "    keywords_exploded\n",
    "      .groupBy(\"keyword\")\n",
    "      .count()\n",
    "      .orderBy(col(\"count\").desc())\n",
    "      .limit(50)\n",
    "      .toPandas()\n",
    ")\n",
    "\n",
    "# 3) Plot as a horizontal bar chart with matplotlib\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(top50[\"keyword\"][::-1], top50[\"count\"][::-1])\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Keyword\")\n",
    "plt.title(\"Top 50 Keywords by Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Explode keywords and carry revenue along\n",
    "keywords_df = df.select(\n",
    "    explode(split(col(\"keywords\"), \"\\\\|\")).alias(\"keyword\"),\n",
    "    col(\"revenue\").cast(\"double\")\n",
    ").filter(col(\"keyword\") != \"\")\n",
    "\n",
    "# 2) Compute frequency and average revenue per keyword\n",
    "kw_stats = (\n",
    "    keywords_df\n",
    "      .groupBy(\"keyword\")\n",
    "      .agg(\n",
    "          count(\"*\").alias(\"frequency\"),\n",
    "          avg(\"revenue\").alias(\"avg_revenue\")\n",
    "      )\n",
    ")\n",
    "\n",
    "# 3) Take top 10 keywords by frequency\n",
    "top10 = (\n",
    "    kw_stats\n",
    "      .orderBy(col(\"frequency\").desc())\n",
    "      .limit(10)\n",
    ")\n",
    "\n",
    "# 4) Show the results in Spark\n",
    "top10.show(truncate=False)\n",
    "\n",
    "# 5) (Optional) Convert to Pandas and plot average revenue\n",
    "pd_top10 = top10.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(pd_top10[\"keyword\"], pd_top10[\"avg_revenue\"])\n",
    "plt.xlabel(\"Keyword\")\n",
    "plt.ylabel(\"Average Revenue\")\n",
    "plt.title(\"Average Revenue for Top 10 Keywords by Frequency\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ecebaa",
   "metadata": {},
   "source": [
    "%md\n",
    "## New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafec851",
   "metadata": {},
   "source": [
    "%md\n",
    "### Profit and ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b157b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with zero or null budget or revenue to avoid division errors\n",
    "df_money = df.filter((col(\"budget\") > 0) & (col(\"revenue\") > 0))\n",
    "\n",
    "# Create 'profit' and 'roi' columns\n",
    "df_money = df_money.withColumn(\"profit\", col(\"revenue\") - col(\"budget\"))\n",
    "df_money = df_money.withColumn(\"roi\", col(\"revenue\") / col(\"budget\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the statistics for 'profit' and 'roi' columns in PySpark\n",
    "df_money.describe(['profit', 'roi']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29bca1",
   "metadata": {},
   "source": [
    "%md\n",
    "#### Check only de ROI > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate profit and ROI\n",
    "df_money = df.withColumn(\"profit\", col(\"revenue\") - col(\"budget\"))\n",
    "df_money = df_money.withColumn(\"roi\", col(\"revenue\") / col(\"budget\"))\n",
    "\n",
    "# Step 2: Filter for positive profit and ROI\n",
    "profit_roi_filtered = df_money.filter((col('profit') > 0) & (col('roi') > 0))\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame for plotting\n",
    "profit_roi_filtered_pd = profit_roi_filtered.select('profit').toPandas()\n",
    "\n",
    "# Step 4: Plot the distribution of profit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(profit_roi_filtered_pd['profit'], bins=100, color='mediumseagreen')\n",
    "plt.title('Distribution of Movie Profit')\n",
    "plt.xlabel('Profit (Revenue - Budget)')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.axvline(0, color='red', linestyle='--', label='Break-even')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d52964",
   "metadata": {},
   "source": [
    "%md\n",
    "#### Movies with the highest profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort by profit in descending order and get the top 10 movies\n",
    "top_profit = profit_roi_filtered.orderBy(col('profit'), ascending=False).limit(10)\n",
    "\n",
    "# Step 2: Select the relevant columns (title, revenue, budget, profit)\n",
    "top_profit_selected = top_profit.select('title', 'revenue', 'budget', 'profit')\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame to display in a table\n",
    "top_profit_selected_pd = top_profit_selected.toPandas()\n",
    "\n",
    "# Step 4: Display the result\n",
    "print(top_profit_selected_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c7688",
   "metadata": {},
   "source": [
    "%md\n",
    "#### Movies with the highest ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort by ROI in descending order and get the top 10 movies\n",
    "top_roi = profit_roi_filtered.orderBy(col('roi'), ascending=False).limit(10)\n",
    "\n",
    "# Step 2: Select the relevant columns (title, budget, revenue, roi)\n",
    "top_roi_selected = top_roi.select('title', 'budget', 'revenue', 'roi')\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame to display in a table\n",
    "top_roi_selected_pd = top_roi_selected.toPandas()\n",
    "\n",
    "# Step 4: Display the result\n",
    "print(top_roi_selected_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111713d",
   "metadata": {},
   "source": [
    "%md\n",
    "## Correlation Matrix for Popularity, Vote_Count and Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas for correlation analysis\n",
    "df_pd = df.select('popularity', 'vote_count', 'revenue').toPandas()\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_popularity = df_pd.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation between Popularity, Vote Count, and Revenue:\")\n",
    "print(correlation_popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c3cff4",
   "metadata": {},
   "source": [
    "%md\n",
    "Vote count appears to have the strongest relationship with revenue.\n",
    "\n",
    "Both popularity and vote count are positively correlated with revenue, but the relationship with popularity is weaker compared to the relationship between vote count and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f159a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the type of each feature\n",
    "df.printSchema()\n",
    "# Function to calculate missing values by column\n",
    "def missing_values_table_spark(df):\n",
    "    \"\"\"\n",
    "    Calculates the total number and percentage of missing (null) values \n",
    "    for each column in a PySpark DataFrame.\n",
    "\n",
    "    Returns a Pandas DataFrame with columns:\n",
    "    - 'Column': column name\n",
    "    - 'Missing Values': count of missing values\n",
    "    - '% of Total Values': percentage of missing values\n",
    "    \n",
    "    Only columns with missing values are included, sorted in descending order.\n",
    "    \"\"\"\n",
    "    # Calculate the total missing values for each column\n",
    "    mis_val = df.select([F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "    # Convert to Pandas for easier handling\n",
    "    mis_val_pd = mis_val.toPandas().transpose()\n",
    "\n",
    "    # Calculate the percentage of missing values for each column\n",
    "    mis_val_percent = (mis_val_pd[0] / df.count()) * 100\n",
    "\n",
    "    # Create a new table combining count and percentage\n",
    "    mis_val_table = pd.concat([mis_val_pd, mis_val_percent], axis=1)\n",
    "    mis_val_table.columns = ['Missing Values', '% of Total Values']\n",
    "\n",
    "    # Keep only columns with >0% missing, sort descending, round\n",
    "    mis_val_table = (\n",
    "        mis_val_table[mis_val_table['% of Total Values'] > 0]\n",
    "        .sort_values('% of Total Values', ascending=False)\n",
    "        .round(1)\n",
    "    )\n",
    "\n",
    "    # Reset index so that original column names become a column\n",
    "    mis_val_table = mis_val_table.reset_index().rename(columns={'index': 'Column'})\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Your selected dataframe has {len(df.columns)} columns.\\n\"\n",
    "          f\"There are {mis_val_table.shape[0]} columns that have missing values.\")\n",
    "\n",
    "    return mis_val_table\n",
    "\n",
    "# Usage\n",
    "missing_values = missing_values_table_spark(df)\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d64aee",
   "metadata": {},
   "source": [
    "%md\n",
    "### Save the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_copy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31030eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save our dataset\n",
    "df.write.mode(\"overwrite\").parquet(\"/FileStore/tables/Imdb_Movie_Dataset-4.csv\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
